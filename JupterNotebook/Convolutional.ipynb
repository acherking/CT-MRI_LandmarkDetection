{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Convolutional Neural Network"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TensorFlow Keras, Layers Conv2D"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 26, 26, 2)\n"
     ]
    }
   ],
   "source": [
    "# The inputs are 28x28 RGB images with `channels_last` and the batch\n",
    "# size is 4.\n",
    "input_shape = (4, 28, 28, 3)\n",
    "x = tf.random.normal(input_shape)\n",
    "y = tf.keras.layers.Conv2D(\n",
    "    2, 3, strides=1, activation='relu', input_shape=input_shape[1:])(x)\n",
    "print(y.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 24, 24, 2)\n"
     ]
    }
   ],
   "source": [
    "# With `dilation_rate` as 2.\n",
    "input_shape = (4, 28, 28, 3)\n",
    "x = tf.random.normal(input_shape)\n",
    "y = tf.keras.layers.Conv2D(\n",
    "    2, 3,\n",
    "    activation='relu',\n",
    "    dilation_rate=2,\n",
    "    input_shape=input_shape[1:])(x)\n",
    "print(y.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 28, 28, 2)\n"
     ]
    }
   ],
   "source": [
    " # With `padding` as \"same\".\n",
    "input_shape = (4, 28, 28, 3)\n",
    "x = tf.random.normal(input_shape)\n",
    "y = tf.keras.layers.Conv2D(\n",
    "    2, 3, activation='relu', padding=\"same\", input_shape=input_shape[1:])(x)\n",
    "print(y.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# With extended batch shape [4, 7]:\n",
    "# input_shape = (4, 7, 28, 28, 3)\n",
    "# x = tf.random.normal(input_shape)\n",
    "# y = tf.keras.layers.Conv2D(\n",
    "#     2, 3, activation='relu', input_shape=input_shape[2:])(x)\n",
    "# print(y.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TensorFlow Keras, Layers Conv3D"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 26, 26, 26, 2)\n",
      "(4, 24, 24, 24, 4)\n",
      "(4, 4)\n"
     ]
    }
   ],
   "source": [
    "# The inputs are 28x28x28 volumes with a single channel, and the\n",
    "# batch size is 4\n",
    "input_shape =(4, 28, 28, 28, 1)\n",
    "x = tf.random.normal(input_shape)\n",
    "x = tf.keras.layers.Conv3D(\n",
    "    2, 3, activation='relu', input_shape=input_shape[1:])(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Conv3D(\n",
    "    4, 3, activation='relu')(x)\n",
    "print(x.shape)\n",
    "y = tf.keras.layers.GlobalAveragePooling3D()(x)\n",
    "print(y.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# # With extended batch shape [4, 7], e.g. a batch of 4 videos of\n",
    "# # 3D frames, with 7 frames per video.\n",
    "# input_shape = (4, 7, 28, 28, 28, 1)\n",
    "# x = tf.random.normal(input_shape)\n",
    "# y = tf.keras.layers.Conv3D(\n",
    "#     2, 3, activation='relu', input_shape=input_shape[2:])(x)\n",
    "# print(y.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Try to build a 3D convolutional neural network for the Landmark Detection project"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ROI_CT_path = '../Resources/ROI_CT.xlsx'\n",
    "ROI_MR_path = '../Resources/ROI_MR.xlsx'\n",
    "\n",
    "roi_CT = pd.read_excel(ROI_CT_path, index_col=[0, 1], header=[0, 1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pname_list = list(set([x for (x, y) in roi_CT.index]))\n",
    "pname_list.sort()\n",
    "\n",
    "print(pname_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pixel_space = [0.15, 0.15, 0.15]\n",
    "data_path_base = \"/Volumes/Shawn_HDD/PhD/Project/Date/CT_Augmented/\"\n",
    "\n",
    "p_name = pname_list[0]\n",
    "data_path = data_path_base + p_name + \"_aug_0.npy\"\n",
    "volume_data = np.load(data_path, allow_pickle=True).item()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import functions\n",
    "\n",
    "functions.show_pts(volume_data.get(\"volume\"), volume_data.get(\"pts\"), pixel_space)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data from .mat --- train, test, valid"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "import h5py"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "\n",
    "# e.g. AZ_17017030_AugVol_1.mat\n",
    "X_train_base_path = \"/Volumes/Shawn_SSD/PhD/Project/Date/augmentation_from_matlab/Train/Input/\"\n",
    "# e.g. AZ_17017030_AugPts_1.mat\n",
    "Y_train_base_path = \"/Volumes/Shawn_SSD/PhD/Project/Date/augmentation_from_matlab/Train/Output/\"\n",
    "\n",
    "X_train_files = [f for f in listdir(X_train_base_path) if isfile(join(X_train_base_path, f))]\n",
    "\n",
    "X_train = []\n",
    "Y_train = []\n",
    "for X_train_file in X_train_files:\n",
    "    X_train_file_path = join(X_train_base_path, X_train_file)\n",
    "    Y_train_file_path = join(Y_train_base_path, X_train_file.replace(\"AugVol\", \"AugPts\"))\n",
    "    file_vol = h5py.File(X_train_file_path, 'r')\n",
    "    file_pts = h5py.File(Y_train_file_path, 'r')\n",
    "    load_mat_vol = file_vol.get('rescaled_aug_vol')\n",
    "    load_mat_pts = file_pts.get('rescaled_aug_pts')\n",
    "    X_train.append(np.array(load_mat_vol).T)\n",
    "    Y_train.append(np.array(load_mat_pts).reshape(3,4).T)\n",
    "    file_vol.close()\n",
    "    file_pts.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "\n",
    "# e.g. AZ_17017030_AugVol_1.mat\n",
    "X_val_base_path = \"/Volumes/Shawn_SSD/PhD/Project/Date/augmentation_from_matlab/Val/Input/\"\n",
    "# e.g. AZ_17017030_AugPts_1.mat\n",
    "Y_val_base_path = \"/Volumes/Shawn_SSD/PhD/Project/Date/augmentation_from_matlab/Val/Output/\"\n",
    "\n",
    "X_val_files = [f for f in listdir(X_val_base_path) if isfile(join(X_val_base_path, f))]\n",
    "\n",
    "X_val = []\n",
    "Y_val = []\n",
    "for X_val_file in X_val_files:\n",
    "    X_val_file_path = join(X_val_base_path, X_val_file)\n",
    "    Y_val_file_path = join(Y_val_base_path, X_val_file.replace(\"AugVol\", \"AugPts\"))\n",
    "    file_vol = h5py.File(X_val_file_path, 'r')\n",
    "    file_pts = h5py.File(Y_val_file_path, 'r')\n",
    "    load_mat_vol = file_vol.get('rescaled_aug_vol')\n",
    "    load_mat_pts = file_pts.get('rescaled_aug_pts')\n",
    "    X_val.append(np.array(load_mat_vol).T)\n",
    "    Y_val.append(np.array(load_mat_pts).reshape(3,4).T)\n",
    "    file_vol.close()\n",
    "    file_pts.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 170, 170, 30)\n",
      "(700, 4, 3)\n",
      "(100, 170, 170, 30)\n",
      "(100, 4, 3)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train))\n",
    "print(np.shape(Y_train))\n",
    "\n",
    "print(np.shape(X_val))\n",
    "print(np.shape(Y_val))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "X_train_reshape = np.asarray(X_train).reshape(700, 170, 170, 30, 1)\n",
    "Y_train = np.asarray(Y_train)[:, 0, :]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "X_val_reshape = np.asarray(X_val).reshape(100, 170, 170, 30, 1)\n",
    "Y_val = np.asarray(Y_val)[:, 0, :]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 3)\n",
      "(700, 170, 170, 30, 1)\n",
      "(100, 3)\n",
      "(100, 170, 170, 30, 1)\n"
     ]
    }
   ],
   "source": [
    "print(Y_train.shape)\n",
    "print(X_train_reshape.shape)\n",
    "\n",
    "print(Y_val.shape)\n",
    "print(X_val_reshape.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train_reshape, Y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1400).batch(2)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val_reshape, Y_val))\n",
    "val_dataset = val_dataset.shuffle(buffer_size=200).batch(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-05 22:57:49.538068: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:143] Filling up shuffle buffer (this may take a while): 486 of 1400\n",
      "2022-10-05 22:57:52.371145: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:193] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:  0\n",
      "x shape:  (2, 170, 170, 30, 1) <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "y shape:  (2, 3) <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "(2, 3)\n",
      "step:  0\n",
      "x shape:  (2, 170, 170, 30, 1) <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "y shape:  (2, 3) <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "(2, 3)\n"
     ]
    }
   ],
   "source": [
    "for step, (x, y) in enumerate(train_dataset):\n",
    "    print(\"step: \", step)\n",
    "    print(\"x shape: \", x.shape, type(x))\n",
    "    print(\"y shape: \", y.shape, type(y))\n",
    "    print(y.shape)\n",
    "    break\n",
    "\n",
    "\n",
    "for step, (x, y) in enumerate(val_dataset):\n",
    "    print(\"step: \", step)\n",
    "    print(\"x shape: \", x.shape, type(x))\n",
    "    print(\"y shape: \", y.shape, type(y))\n",
    "    print(y.shape)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define data loaders.\n",
    "train_loader = tf.data.Dataset.from_tensor_slices((X_train_reshape, Y_train))\n",
    "validation_loader = tf.data.Dataset.from_tensor_slices((X_val_reshape, Y_val))\n",
    "\n",
    "batch_size = 2\n",
    "train_dataset = (\n",
    "    train_loader.shuffle(len(X_train_reshape))\n",
    "    .batch(batch_size)\n",
    "    .prefetch(2)\n",
    ")\n",
    "# Only rescale.\n",
    "validation_dataset = (\n",
    "    validation_loader.shuffle(len(X_val))\n",
    "    .batch(batch_size)\n",
    "    .prefetch(2)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"3dcnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 170, 170, 30, 1)] 0         \n",
      "_________________________________________________________________\n",
      "conv3d_15 (Conv3D)           (None, 168, 168, 28, 64)  1792      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_5 (MaxPooling3 (None, 84, 84, 14, 64)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 84, 84, 14, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv3d_16 (Conv3D)           (None, 82, 82, 12, 64)    110656    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_6 (MaxPooling3 (None, 41, 41, 6, 64)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 41, 41, 6, 64)     256       \n",
      "_________________________________________________________________\n",
      "conv3d_17 (Conv3D)           (None, 39, 39, 4, 128)    221312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 39, 39, 4, 128)    512       \n",
      "_________________________________________________________________\n",
      "conv3d_18 (Conv3D)           (None, 37, 37, 2, 256)    884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 37, 37, 2, 256)    1024      \n",
      "_________________________________________________________________\n",
      "global_average_pooling3d_4 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 1,353,923\n",
      "Trainable params: 1,352,899\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras.layers as layers\n",
    "\n",
    "def get_model(width=170, height=170, depth=30):\n",
    "    \"\"\"Build a 3D convolutional neural network model.\"\"\"\n",
    "\n",
    "    inputs = keras.Input((width, height, depth, 1))\n",
    "\n",
    "    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(inputs)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv3D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "    #x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv3D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "    #x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling3D()(x)\n",
    "    x = layers.Dense(units=512, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    outputs = layers.Dense(units=3, )(x)\n",
    "\n",
    "    # Define the model.\n",
    "    model = keras.Model(inputs, outputs, name=\"3dcnn\")\n",
    "    return model\n",
    "\n",
    "# Build model.\n",
    "model = get_model(width=170, height=170, depth=30)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-05 23:37:52.505957: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,val_loss\n",
      "350/350 - 2233s - loss: 4501.3702 - val_loss: 0.0000e+00\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-06 00:14:03.569328: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,val_loss\n",
      "350/350 - 2171s - loss: 1087.9394 - val_loss: 4647.5551\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-06 00:50:13.563154: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,val_loss\n",
      "350/350 - 2170s - loss: 742.1464 - val_loss: 3834.3984\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-06 01:26:26.161024: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,val_loss\n",
      "350/350 - 2173s - loss: 768.7369 - val_loss: 1988.8743\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-06 02:02:38.600756: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,val_loss\n",
      "350/350 - 2173s - loss: 702.0161 - val_loss: 5322.8127\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-06 02:38:49.532611: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,val_loss\n",
      "350/350 - 2171s - loss: 790.2238 - val_loss: 4205.9577\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-06 03:15:00.195065: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,val_loss\n",
      "350/350 - 2171s - loss: 623.8895 - val_loss: 4907.7932\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-06 03:51:11.212343: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,val_loss\n",
      "350/350 - 2171s - loss: 562.0425 - val_loss: 2837.6959\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-06 04:27:20.485277: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,val_loss\n",
      "350/350 - 2169s - loss: 543.5352 - val_loss: 3778.9273\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-06 05:03:28.741691: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,val_loss\n",
      "350/350 - 2169s - loss: 568.8740 - val_loss: 2585.7698\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-06 05:39:39.982742: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,val_loss\n",
      "350/350 - 2171s - loss: 498.2467 - val_loss: 3067.8204\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-06 06:15:50.136772: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,val_loss\n",
      "350/350 - 2170s - loss: 466.0888 - val_loss: 2638.3620\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-06 06:52:03.766575: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,val_loss\n",
      "350/350 - 2173s - loss: 502.6264 - val_loss: 2829.4910\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-06 07:28:11.869814: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,val_loss\n",
      "350/350 - 2169s - loss: 573.3435 - val_loss: 1580.2973\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-06 08:04:37.712681: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,val_loss\n",
      "350/350 - 2189s - loss: 462.4776 - val_loss: 2304.8940\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-06 08:41:09.988847: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,val_loss\n",
      "350/350 - 2189s - loss: 498.0463 - val_loss: 1679.8490\n",
      "Epoch 17/100\n"
     ]
    }
   ],
   "source": [
    "# Compile model.\n",
    "initial_learning_rate = 0.0001\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n",
    ")\n",
    "model.compile(\n",
    "    loss=\"mean_squared_error\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "    #metrics=[\"acc\"],\n",
    ")\n",
    "\n",
    "# Define callbacks.\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "    \"3d_image_classification.h5\", save_best_only=True\n",
    ")\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(monitor=\"val_acc\", patience=15)\n",
    "\n",
    "# Train the model, doing validation at the end of each epoch\n",
    "epochs = 100\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=epochs,\n",
    "    shuffle=True,\n",
    "    verbose=2,\n",
    "    callbacks=[checkpoint_cb, early_stopping_cb],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}