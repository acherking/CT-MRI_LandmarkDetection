{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Use regression model to locate the landmark point"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ROI_CT_path = '../Resources/ROI_CT.xlsx'\n",
    "ROI_MR_path = '../Resources/ROI_MR.xlsx'\n",
    "\n",
    "roi_CT = pd.read_excel(ROI_CT_path, index_col=[0, 1], header=[0, 1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pname_list = list(set([x for (x, y) in roi_CT.index]))\n",
    "pname_list.sort()\n",
    "\n",
    "print(pname_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pixel_space = [0.15, 0.15, 0.15]\n",
    "data_path_base = \"/Volumes/ExternalDis/PhD/Project/Date/CT_Augmented/\"\n",
    "\n",
    "p_name = pname_list[0]\n",
    "data_path = data_path_base + p_name + \"_aug_0.npy\"\n",
    "volume_data = np.load(data_path, allow_pickle=True).item()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import functions\n",
    "\n",
    "functions.show_pts(volume_data.get(\"volume\"), volume_data.get(\"pts\"), pixel_space)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Try regression model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array(\n",
    "    [56755.72171242, 44178.04737774, 40991.80813814, 8814.00098681, 43585.51198178, 13574.17183072, 6175.8760297,\n",
    "     17829.69832237, 53254.85637009, 17522.23018625, 42784.69836164, 36638.18492916, 41086.72967373, 18167.77372717,\n",
    "     12706.89121489, 52564.42917946, 61995.42280258, 35776.79516181, 30230.22630213, 34524.46986093, 13774.60527391,\n",
    "     14258.22933451, 101376.49657434, 9616.64500569, 45175.23189338, 38615.99518491, 74355.51585756, 12578.49547344,\n",
    "     19242.3664711, 16310.988409, 20881.76692993, 5734.63362915, 25732.01836475, 51545.48360953, 82081.59716162,\n",
    "     11006.2497364, 44974.83187718, 56839.38177423])\n",
    "y = np.array(\n",
    "    [7.3, 7.1, 6.9, 6.4, 7.4, 6.5, 6.3, 6.7, 7.6, 5.7, 7.6, 6.5, 7.0, 5.4, 5.6, 7.5, 7.0, 7.2, 6.0, 5.9, 5.9, 5.9, 6.9,\n",
    "     6.5, 7.4, 7.3, 7.6, 6.1, 5.4, 6.2, 5.9, 4.7, 6.3, 7.3, 7.5, 5.5, 6.8, 6.9])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Polyfit of NumPy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "p = np.poly1d(np.polyfit(x, y, 1))\n",
    "print(p)\n",
    "x_line = np.linspace(np.amin(x), np.amax(x), 200)\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x_line, p(x_line))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Linregress of SciPy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import scipy as sc\n",
    "from scipy import stats\n",
    "\n",
    "regr_results = sc.stats.linregress(x, y)\n",
    "print(regr_results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. OLS and ols of statsmodels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "x = sm.add_constant(x) # Adds an intercept term to the simple linear regression formula\n",
    "lin_model = sm.OLS(y, x)\n",
    "reg_results = lin_model.fit()\n",
    "print(regr_results.params)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. LinearRegression of scikit-learn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "lin_model = linear_model.LinearRegression(fit_intercept=True)\n",
    "lin_model.fit(x.reshape(-1, 1), y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(slope, intercept) = (lin_model.coef_[0], lin_model.intercept_)\n",
    "print(slope, intercept)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5. regplot of seaborn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.regplot(x = x, y = y, ci=95, order=1,line_kws={'label': 'Linear regression line: $Y(X)=5.74+2.39\\cdot 10^{-5} X$', 'color': 'm'}, seed=1,truncate=False, label=\"Original data\")\n",
    "ax.set_xlabel(\"GDP per capita 2015 (USD)\")\n",
    "ax.set_ylabel(\"Life Satisfaction Value\")\n",
    "ax.set_xticks([1000, 10000, 20000, 30000, 40000, 50000, 60000, 70000, 80000, 90000, 100000])\n",
    "ax.set_yticks(np.arange(3.0, 10.5, 0.5))\n",
    "ax.legend(loc=\"upper left\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Try some DNN models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data from .mat --- train, validate, test."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "import h5py"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# e.g. AZ_17017030_AugVol_1.mat\n",
    "X_train_base_path = \"/Volumes/Shawn_SSD/PhD/Project/Date/augmentation_from_matlab/Train/Input/\"\n",
    "# e.g. AZ_17017030_AugPts_1.mat\n",
    "Y_train_base_path = \"/Volumes/Shawn_SSD/PhD/Project/Date/augmentation_from_matlab/Train/Output/\"\n",
    "\n",
    "X_train_files = [f for f in listdir(X_train_base_path) if isfile(join(X_train_base_path, f))]\n",
    "\n",
    "X_train = []\n",
    "Y_train = []\n",
    "for X_train_file in X_train_files:\n",
    "    X_train_file_path = join(X_train_base_path, X_train_file)\n",
    "    Y_train_file_path = join(Y_train_base_path, X_train_file.replace(\"AugVol\", \"AugPts\"))\n",
    "    file_vol = h5py.File(X_train_file_path, 'r')\n",
    "    file_pts = h5py.File(Y_train_file_path, 'r')\n",
    "    load_mat_vol = file_vol.get('rescaled_aug_vol')\n",
    "    load_mat_pts = file_pts.get('rescaled_aug_pts')\n",
    "    X_train.append(np.array(load_mat_vol).T)\n",
    "    Y_train.append(np.array(load_mat_pts).reshape(3,4).T)\n",
    "    file_vol.close()\n",
    "    file_pts.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.shape(X_train))\n",
    "print(np.shape(Y_train))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train_reshape = np.asarray(X_train).reshape(700, 170*170*30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.asarray(Y_train)[:, 0, :].shape)\n",
    "print(X_train_reshape.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_train_reshape, Y_train))\n",
    "dataset = dataset.shuffle(buffer_size=1400).batch(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for step, (x, y) in enumerate(dataset):\n",
    "    print(\"step: \", step)\n",
    "    print(\"x shape: \", x.shape, type(x))\n",
    "    print(\"y shape: \", y.shape, type(y))\n",
    "    print(y[:, 0, :].shape)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Linear(keras.layers.Layer):\n",
    "    \"\"\"y = w.x + b\"\"\"\n",
    "\n",
    "    def __init__(self, units=32):\n",
    "        super(Linear, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(\n",
    "            shape=(input_shape[-1], self.units),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            shape=(self.units,), initializer=\"random_normal\", trainable=True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MyMap(keras.layers.Layer):\n",
    "    \"\"\"y = x .* w\"\"\"\n",
    "\n",
    "    def __init__(self, units=32):\n",
    "        super(Linear, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(\n",
    "            shape=(input_shape[-1], 1),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            shape=(self.units,), initializer=\"random_normal\", trainable=True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        m = tf.math.multiply(inputs, self.w)\n",
    "        m = tf.reshape(m, (inputs.shape[0], 170, 170, 30))\n",
    "        m = tf.math.reduce_sum(m, 3)\n",
    "        m = tf.reshape(m, (inputs.shape[0], 170*170))\n",
    "        return m\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class SimpleMLP(keras.layers.Layer):\n",
    "    \"\"\"Simple stack of Linear layers.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.linear_1 = Linear(1020)\n",
    "        #self.linear_2 = Linear(512)\n",
    "        self.linear_3 = Linear(3)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.linear_1(inputs)\n",
    "        #x = self.linear_2(x)\n",
    "        return self.linear_3(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class TestMLP(keras.layers.Layer):\n",
    "    \"\"\"Linear layers with some architecture.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(TestMLP, self).__init__()\n",
    "        self.my_map = MyMap(170*170)\n",
    "        self.linear_1 = Linear(1020)\n",
    "        self.linear_2 = Linear(512)\n",
    "        self.linear_3 = Linear(3)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.my_map(inputs)\n",
    "        x = self.linear_1(x)\n",
    "        x = self.linear_2(x)\n",
    "        return self.linear_3(x)\n",
    "\n",
    "mlp = SimpleMLP()\n",
    "\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-15)\n",
    "\n",
    "# Create a training step function.\n",
    "\n",
    "#@tf.function  # Make it fast.\n",
    "def train_on_batch(x,y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pre = mlp(x)\n",
    "        loss = loss_fn(y[:,0,:], y_pre)\n",
    "        gradients = tape.gradient(loss, mlp.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, mlp.trainable_weights))\n",
    "    return loss\n",
    "\n",
    "\n",
    "# Iterate over the batches of the dataset.\n",
    "for step, (x, y) in enumerate(dataset):\n",
    "    loss = train_on_batch(x, y)\n",
    "    if step % 1 == 0:\n",
    "        print(\"Step:\", step, \"Loss:\", float(loss))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}