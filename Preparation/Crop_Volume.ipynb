{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Crop the 3D Volume based on some points"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## To find out the suitable crop size.\n",
    "## based on ROI points\n",
    "import Functions.MyDataset as MyDataset\n",
    "import importlib\n",
    "\n",
    "importlib.reload(MyDataset)\n",
    "\n",
    "name_list, pts = MyDataset.load_data_dir(\"/Volumes/Shawn_HDD/PhD/Project/Date/augmentation_from_matlab/original_augmentation_data/\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "max_diff_x = 0\n",
    "max_diff_y = 0\n",
    "max_diff_z = 0\n",
    "\n",
    "for patient in range(pts.shape[0]):\n",
    "    diff_x = max([abs(pts[patient, 0, 0]-pts[patient, 1, 0]), abs(pts[patient, 0, 0]-pts[patient, 2, 0]),\n",
    "                  abs(pts[patient, 0, 0]-pts[patient, 3, 0])])\n",
    "    max_diff_x = max([max_diff_x, diff_x])\n",
    "    diff_y = max([abs(pts[patient, 0, 1]-pts[patient, 1, 1]), abs(pts[patient, 0, 1]-pts[patient, 2, 1]),\n",
    "                  abs(pts[patient, 0, 1]-pts[patient, 3, 1])])\n",
    "    max_diff_y = max([max_diff_y, diff_y])\n",
    "    diff_z = max([abs(pts[patient, 0, 2]-pts[patient, 1, 2]), abs(pts[patient, 0, 2]-pts[patient, 2, 2]),\n",
    "                  abs(pts[patient, 0, 2]-pts[patient, 3, 2])])\n",
    "    max_diff_z = max([max_diff_z, diff_z])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"max_diff_x: \", max_diff_x)\n",
    "print(\"max_diff_y: \", max_diff_y)\n",
    "print(\"max_diff_z: \", max_diff_z)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Looks like the area is still too big (598, 188, 169)\n",
    "So, we think we can focus on the left and right landmark area separately"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Check the cropped results\n",
    "import numpy as np\n",
    "import importlib\n",
    "import Functions.MyDataset as MyDataset\n",
    "import Functions.Visualization as Visualization\n",
    "\n",
    "JH_aug_mat_path = \"/Volumes/Shawn_HDD/PhD/Project/Date/augmentation_from_matlab/original_augmentation_data/AZ_aug_10.mat\"\n",
    "# JH_reshape_vol_mat_path = \"/Volumes/Shawn_SSD/PhD/Project/Date/augmentation_from_matlab/Val/Input/FA_17017030_AugVol_2.mat\"\n",
    "# JH_reshape_pts_mat_path = \"/Volumes/Shawn_SSD/PhD/Project/Date/augmentation_from_matlab/Val/Output/FA_17017030_AugPts_2.mat\"\n",
    "\n",
    "pixel_space = [0.15, 0.15, 0.15]\n",
    "\n",
    "importlib.reload(MyDataset)\n",
    "\n",
    "JH_aug_volume, JH_aug_pts, _ = MyDataset.load_mat_data(JH_aug_mat_path)\n",
    "\n",
    "Visualization.show_pts(JH_aug_volume, JH_aug_pts, pixel_space)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T11:25:27.233225Z",
     "end_time": "2023-05-02T11:26:10.468482Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import Functions.MyCrop as MyCrop\n",
    "\n",
    "crop_s = ((50, 50), (50, 50), (50, 50))\n",
    "left_volume, left_points, left_length, right_volume, right_points, right_length = MyCrop.crop_volume(JH_aug_volume, JH_aug_pts, crop_s)\n",
    "flip_right_volume, flip_right_points = MyCrop.flip_volume(right_volume, right_points)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Original Points: \", JH_aug_pts)\n",
    "print(\"Locate back: \", np.append(left_points + left_length, right_points + right_length, axis=0))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "importlib.reload(Visualization)\n",
    "import time\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "pixel_space = [0.15, 0.15, 0.15]\n",
    "\n",
    "Visualization.show_two_landmarks(left_volume, left_points, flip_right_volume, flip_right_points, pixel_space)\n",
    "\n",
    "# for i in range(100):\n",
    "#     left_points[0][2] = i\n",
    "#     left_points[1][2] = i\n",
    "#     flip_right_points[0][2] = i\n",
    "#     flip_right_points[1][2] = i\n",
    "#     Visualization.show_two_landmarks(left_volume, left_points, flip_right_volume, flip_right_points, pixel_space)\n",
    "#     time.sleep(1)\n",
    "#     clear_output(wait=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Crop the augmented volumes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import Functions.MyDataset as MyDataset\n",
    "\n",
    "# store cropped volumes into one arrays, and points to another\n",
    "pixel_space = [0.15, 0.15, 0.15]\n",
    "dir_path = \"F:/Data/original_augmentation_data/\"\n",
    "save_volumes_dir = \"F:/Data/cropped/x5050y5050z5050/volumes/\"\n",
    "save_points_dir = \"F:/Data/cropped/x5050y5050z5050/points/\"\n",
    "save_length_dir = \"F:/Data/cropped/x5050y5050z5050/length/\"\n",
    "pat_names = MyDataset.get_pat_names()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for pat_name in pat_names:\n",
    "    for aug_id in range(1, 51):\n",
    "        # such as: \"/Volumes/Shawn_HDD/PhD/Project/Date/augmentation_from_matlab/original_augmentation_data/AH_aug_1.mat\"\n",
    "        file_path = dir_path + pat_name + \"_aug_\" + str(aug_id) + \".mat\"\n",
    "        print(\"load file: \", file_path)\n",
    "        aug_volume, aug_pts, _ = MyDataset.load_mat_data(file_path)\n",
    "        clear_output(wait=True)\n",
    "        print(\"crop volume for: \", file_path)\n",
    "        left_volume, left_points, left_length, right_volume, right_points, right_length = MyCrop.crop_volume(aug_volume, aug_pts)\n",
    "        flip_right_volume, flip_right_points = MyCrop.flip_volume(right_volume, right_points)\n",
    "        Visualization.show_two_landmarks(left_volume, left_points, flip_right_volume, flip_right_points, pixel_space)\n",
    "        print(\"save the cropped volumes\")\n",
    "        np.save(save_volumes_dir + pat_name + \"_augVolume_\"+str(aug_id)+\"_cropped_left.npy\", left_volume)\n",
    "        np.save(save_volumes_dir + pat_name + \"_augVolume_\"+str(aug_id)+\"_cropped_right.npy\", flip_right_volume)\n",
    "        np.save(save_points_dir + pat_name + \"_augPoints_\"+str(aug_id)+\"_cropped_left.npy\", left_points)\n",
    "        np.save(save_points_dir + pat_name + \"_augLength_\"+str(aug_id)+\"_cropped_left.npy\", left_length)\n",
    "        np.save(save_length_dir + pat_name + \"_augPoints_\"+str(aug_id)+\"_cropped_right.npy\", flip_right_points)\n",
    "        np.save(save_length_dir + pat_name + \"_augLength_\"+str(aug_id)+\"_cropped_right.npy\", right_length)\n",
    "        print(\"Finish cropping: \" + file_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Combine cropped volumes\n",
    "cropped_volumes = []\n",
    "cropped_points = []\n",
    "cropped_length = []\n",
    "\n",
    "for pat_name in pat_names:\n",
    "    for aug_id in range(1, 51):\n",
    "        # such as: \"F:/Data/cropped/x5050y5050z5050/volumes/AH_augVolume_1_cropped_left_100x100x100.npy\"\n",
    "        #          \"F:/Data/cropped/x5050y5050z5050/volumes/AH_augVolume_1_cropped_right_100x100x100.npy\"\n",
    "        #          \"F:/Data/cropped/x5050y5050z5050/points/AH_augPoints_1_cropped_left_100x100x100.npy\"\n",
    "        #          \"F:/Data/cropped/x5050y5050z5050/points/AH_augPoints_1_cropped_right_100x100x100.npy\"\n",
    "        print(\"**************\" + pat_name + \"__\" + str(aug_id) + \"***************\")\n",
    "        cropped_volume_left_path = save_volumes_dir + pat_name + \"_augVolume_\" + str(aug_id) + \"_cropped_left.npy\"\n",
    "        cropped_volume_right_path = save_volumes_dir + pat_name + \"_augVolume_\" + str(aug_id) + \"_cropped_right.npy\"\n",
    "        cropped_points_left_path = save_points_dir + pat_name + \"_augPoints_\" + str(aug_id) + \"_cropped_left.npy\"\n",
    "        cropped_length_left_path = save_length_dir + pat_name + \"_augLength_\" + str(aug_id) + \"_cropped_left.npy\"\n",
    "        cropped_points_right_path = save_points_dir + pat_name + \"_augPoints_\" + str(aug_id) + \"_cropped_right.npy\"\n",
    "        cropped_length_right_path = save_length_dir + pat_name + \"_augLength_\" + str(aug_id) + \"_cropped_right.npy\"\n",
    "        cropped_volume_left = np.load(cropped_volume_left_path)\n",
    "        cropped_volume_right = np.load(cropped_volume_right_path)\n",
    "        cropped_points_left = np.load(cropped_points_left_path)\n",
    "        cropped_length_left = np.load(cropped_length_left_path)\n",
    "        cropped_points_right = np.load(cropped_points_right_path)\n",
    "        cropped_length_right = np.load(cropped_length_right_path)\n",
    "        cropped_volumes.append(cropped_volume_left)\n",
    "        cropped_volumes.append(cropped_volume_right)\n",
    "        cropped_points.append(cropped_points_left)\n",
    "        cropped_points.append(cropped_points_right)\n",
    "        cropped_length.append(cropped_length_left)\n",
    "        cropped_length.append(cropped_length_right)\n",
    "\n",
    "print(len(cropped_volumes))\n",
    "print(len(cropped_points))\n",
    "print(len(cropped_length))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cropped_volumes = np.asarray(cropped_volumes).reshape((2000, 100, 100, 100, 1))\n",
    "cropped_points = np.asarray(cropped_points).reshape((2000, 2, 3))\n",
    "cropped_length = np.asarray(cropped_length).reshape((2000, 2, 3))\n",
    "np.save(\"F:/Data/cropped/cropped_volumes_x5050y5050z5050.npy\", cropped_volumes)\n",
    "np.save(\"F:/Data/cropped/cropped_points_x5050y5050z5050.npy\", cropped_points)\n",
    "np.save(\"F:/Data/cropped/cropped_length_x5050y5050z5050.npy\", cropped_length)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"cropped_volumes shape: \", cropped_volumes.shape)\n",
    "print(\"cropped_points shape: \", cropped_points.shape)\n",
    "print(\"cropped_length shape: \", cropped_length.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check the Combined cropped volumes\n",
    "import Functions.Visualization as Visualization\n",
    "\n",
    "pat_id = 0\n",
    "Visualization.show_two_landmarks(cropped_volumes[pat_id].reshape(100,100,100), cropped_points[pat_id],\n",
    "                                 cropped_volumes[pat_id+1].reshape(100,100,100), cropped_points[pat_id+1], pixel_space)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculate the cropped_length"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "landmarks_path = \"/Volumes/Shawn_HDD/PhD/Project/Date/augmentation_from_matlab/original_augmentation_data/AH_aug_2.mat\"\n",
    "volume_size_path = \"/Volumes/Shawn_HDD/PhD/Project/Date/augmentation_from_matlab/original_augmentation_volume_size/AH_augSize_2.mat\"\n",
    "\n",
    "landmarks_file = h5py.File(landmarks_path, 'r')\n",
    "volume_size_file= h5py.File(volume_size_path, 'r')\n",
    "\n",
    "landmarks_cropped_check = np.load(\"/Volumes/Shawn_HDD/PhD/Project/Date/augmentation_from_matlab/Cropped/cropped_points_x5050y5050z5050.npy\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T12:31:12.160944Z",
     "end_time": "2023-05-02T12:31:12.177264Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "landmarks = np.asarray(landmarks_file.get('augPts')).reshape(3, 4).T\n",
    "volume_size = np.asarray(volume_size_file.get('volumeSize'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T12:31:15.319685Z",
     "end_time": "2023-05-02T12:31:15.329316Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "import Functions.MyCrop as MyCrop\n",
    "\n",
    "importlib.reload(MyCrop)\n",
    "\n",
    "left_landmarks, left_cropped_length, right_landmarks, right_cropped_length = MyCrop.crop_volume_shape(volume_size, landmarks)\n",
    "\n",
    "right_landmarks_flipped = MyCrop.flip_volume_shape((100, 100, 100), right_landmarks)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T12:39:23.026918Z",
     "end_time": "2023-05-02T12:39:23.039214Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "\n",
    "left_landmarks_check = landmarks_cropped_check[2]\n",
    "right_landmarks_check = landmarks_cropped_check[3]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T12:39:24.415127Z",
     "end_time": "2023-05-02T12:39:24.431750Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_landmarks cropped: [[51.15975662 34.59953945 50.23935345]\n",
      " [47.58622571 64.19868863 47.97655764]]\n",
      "left_landmarks check: [[52.15975662 35.59953945 51.23935345]\n",
      " [48.58622571 65.19868863 48.97655764]]\n",
      "right_landmarks cropped: [[57.42920872 36.96424741 52.87746313]\n",
      " [41.3167736  62.23752452 46.90662578]]\n",
      "right_landmarks check: [[56.42920872 37.96424741 53.87746313]\n",
      " [40.3167736  63.23752452 47.90662578]]\n"
     ]
    }
   ],
   "source": [
    "print(\"left_landmarks cropped:\", left_landmarks)\n",
    "print(\"left_landmarks check:\", left_landmarks_check)\n",
    "print(\"right_landmarks cropped:\", right_landmarks_flipped)\n",
    "print(\"right_landmarks check:\", right_landmarks_check)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T12:39:39.961043Z",
     "end_time": "2023-05-02T12:39:39.973321Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[786.15975662 501.59953945 226.23935345]\n",
      " [782.58622571 531.19868863 223.97655764]\n",
      " [277.57079128 586.96424741 225.87746313]\n",
      " [293.6832264  612.23752452 219.90662578]]\n"
     ]
    }
   ],
   "source": [
    "print(landmarks)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T12:46:32.883033Z",
     "end_time": "2023-05-02T12:46:32.895494Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[786.15975662 501.59953945 226.23935345]\n",
      " [782.58622571 531.19868863 223.97655764]]\n",
      "[[277.57079128 586.96424741 225.87746313]\n",
      " [293.6832264  612.23752452 219.90662578]]\n"
     ]
    }
   ],
   "source": [
    "print(left_landmarks_check+left_cropped_length-1)\n",
    "\n",
    "right_landmarks_check_flipped = MyCrop.flip_volume_shape((100, 100, 100), right_landmarks_check)\n",
    "print(right_landmarks_check_flipped+right_cropped_length-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T12:49:57.552789Z",
     "end_time": "2023-05-02T12:49:57.578168Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "aug_dir = \"/Volumes/Shawn_HDD/PhD/Project/Date/augmentation_from_matlab/original_augmentation_data/\"\n",
    "size_dir = \"/Volumes/Shawn_HDD/PhD/Project/Date/augmentation_from_matlab/original_augmentation_volume_size/\"\n",
    "\n",
    "pat_names = MyDataset.get_pat_names()\n",
    "\n",
    "cropped_length = None\n",
    "for pat_name in pat_names:\n",
    "    for aug_id in range(1, 51):\n",
    "        aug_file_path = f\"{aug_dir}{pat_name}_aug_{aug_id}.mat\"\n",
    "        size_file_path = f\"{size_dir}{pat_name}_augSize_{aug_id}.mat\"\n",
    "        aug_file = h5py.File(aug_file_path, 'r')\n",
    "        size_file = h5py.File(size_file_path, 'r')\n",
    "        landmarks = np.asarray(aug_file.get('augPts')).reshape(3, 4).T\n",
    "        volume_size = np.asarray(size_file.get('volumeSize'))\n",
    "        left_landmarks, left_cropped_length, right_landmarks, right_cropped_length = \\\n",
    "            MyCrop.crop_volume_shape(volume_size, landmarks)\n",
    "        c_length = np.concatenate((left_cropped_length, right_cropped_length), axis=0)\n",
    "        # combine the cropped length\n",
    "        if cropped_length is None:\n",
    "            cropped_length = c_length\n",
    "        else:\n",
    "            cropped_length = np.concatenate((cropped_length, c_length), axis=0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T13:41:06.233006Z",
     "end_time": "2023-05-02T13:42:08.397700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "cropped_length = cropped_length.reshape((2000, 2, 3))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T13:43:06.851278Z",
     "end_time": "2023-05-02T13:43:06.879661Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[786.15975662 501.59953945 226.23935345]\n",
      " [782.58622571 531.19868863 223.97655764]]\n",
      "[[277.57079128 586.96424741 225.87746313]\n",
      " [293.6832264  612.23752452 219.90662578]]\n"
     ]
    }
   ],
   "source": [
    "print(left_landmarks_check+cropped_length[2]-1)\n",
    "\n",
    "right_landmarks_check_flipped = MyCrop.flip_volume_shape((100, 100, 100), right_landmarks_check)\n",
    "print(right_landmarks_check_flipped+cropped_length[3]-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T13:43:53.627918Z",
     "end_time": "2023-05-02T13:43:53.636604Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "np.save(\"/Volumes/Shawn_HDD/PhD/Project/Date/augmentation_from_matlab/Cropped/cropped_length_x5050y5050z5050.npy\", cropped_length)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T13:55:11.208314Z",
     "end_time": "2023-05-02T13:55:11.243647Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
