{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Process the data (combine them together)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Check JH's augmentation data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import importlib\n",
    "import functions\n",
    "\n",
    "JH_aug_mat_path = \"/Volumes/Shawn_SSD/PhD/Project/Date/Tmp/JH_Pre_Augmentation/original_augmentation_data/JH_aug_2.mat\"\n",
    "JH_reshape_vol_mat_path = \"/Volumes/Shawn_SSD/PhD/Project/Date/augmentation_from_matlab/Val/Input/FA_17017030_AugVol_2.mat\"\n",
    "JH_reshape_pts_mat_path = \"/Volumes/Shawn_SSD/PhD/Project/Date/augmentation_from_matlab/Val/Output/FA_17017030_AugPts_2.mat\"\n",
    "\n",
    "pixel_space = [0.15, 0.15, 0.15]\n",
    "\n",
    "importlib.reload(functions)\n",
    "\n",
    "# JH_aug_volume, JH_aug_pts = functions.load_mat_data(JH_aug_mat_path)\n",
    "# functions.show_pts(JH_aug_volume, JH_aug_pts, pixel_space)\n",
    "\n",
    "JH_aug_zoomed_volume, JH_aug_zoomed_pts = functions.load_mat_data(JH_reshape_vol_mat_path, JH_reshape_pts_mat_path)\n",
    "functions.show_pts(JH_aug_zoomed_volume, JH_aug_zoomed_pts, pixel_space)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Try up_sampling method\n",
    "\n",
    "up_sampling_JH = functions.rescale_3d_volume(JH_aug_zoomed_volume, (512, 512, 90))\n",
    "functions.show_pts(up_sampling_JH, JH_aug_zoomed_pts, pixel_space)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Combination"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import importlib\n",
    "import functions\n",
    "\n",
    "def combine_data(x_base_path, y_base_path, store_base_path, data_tag):\n",
    "    importlib.reload(functions)\n",
    "\n",
    "    # X_val_base_path = \"/Volumes/Shawn_SSD/PhD/Project/Date/augmentation_from_matlab/Val/Input\"\n",
    "    # Y_val_base_path = \"/Volumes/Shawn_SSD/PhD/Project/Date/augmentation_from_matlab/Val/Output\"\n",
    "\n",
    "    x_dataset, y_dataset = functions.load_mat_data_dir(x_base_path, y_base_path)\n",
    "\n",
    "    x_dataset = np.asarray(x_dataset)\n",
    "    y_dataset = np.asarray(y_dataset)\n",
    "\n",
    "    x_dataset_path = store_base_path + \"X_\" + data_tag + \"_data\"\n",
    "    y_dataset_path = store_base_path + \"Y_\" + data_tag + \"_data\"\n",
    "\n",
    "    np.save(x_dataset_path, x_dataset)\n",
    "    np.save(y_dataset_path, y_dataset)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "X_train_base_path = \"/Volumes/Shawn_SSD/PhD/Project/Date/augmentation_from_matlab/Train/Input\"\n",
    "Y_train_base_path = \"/Volumes/Shawn_SSD/PhD/Project/Date/augmentation_from_matlab/Train/Output\"\n",
    "X_val_base_path = \"/Volumes/Shawn_SSD/PhD/Project/Date/augmentation_from_matlab/Val/Input\"\n",
    "Y_val_base_path = \"/Volumes/Shawn_SSD/PhD/Project/Date/augmentation_from_matlab/Val/Output\"\n",
    "X_test_base_path = \"/Volumes/Shawn_SSD/PhD/Project/Date/augmentation_from_matlab/Test/Input\"\n",
    "Y_test_base_path = \"/Volumes/Shawn_SSD/PhD/Project/Date/augmentation_from_matlab/Test/Output\"\n",
    "store_base_path = \"data/\"\n",
    "\n",
    "combine_data(X_train_base_path, Y_train_base_path, store_base_path, \"train\")\n",
    "combine_data(X_val_base_path, Y_val_base_path, store_base_path, \"val\")\n",
    "combine_data(X_test_base_path, Y_test_base_path, store_base_path, \"test\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 170, 170, 30) (700, 4, 3)\n",
      "(170, 170, 30) (4, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import functions\n",
    "\n",
    "# Inspect Loaded Data\n",
    "\n",
    "X_file_path = \"data/X_train_data.npy\"\n",
    "Y_file_path = \"data/Y_train_data.npy\"\n",
    "\n",
    "X_load = np.load(X_file_path, allow_pickle=True)\n",
    "Y_load = np.load(Y_file_path, allow_pickle=True)\n",
    "\n",
    "print(np.shape(X_load), np.shape(Y_load))\n",
    "print(np.shape(X_load[1, :, :, :]), np.shape(Y_load[1, :, :]))\n",
    "\n",
    "# functions.show_pts(X_load[1, :, :, :], Y_load[1, :, :], [0.15, 0.15, 0.15])\n",
    "# functions.show_pts(X_load[2, :, :, :], Y_load[2, :, :], [0.15, 0.15, 0.15])\n",
    "# functions.show_pts(X_load[3, :, :, :], Y_load[3, :, :], [0.15, 0.15, 0.15])\n",
    "# functions.show_pts(X_load[4, :, :, :], Y_load[4, :, :], [0.15, 0.15, 0.15])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import Spartan.models as models\n",
    "\n",
    "model_s1, model_s2 = models.spine_lateral_radiograph()\n",
    "\n",
    "model_s1.summary()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [2]\u001B[0m, in \u001B[0;36m<cell line: 64>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     56\u001B[0m     model\u001B[38;5;241m.\u001B[39mcompile(\n\u001B[1;32m     57\u001B[0m         optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madam\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     58\u001B[0m         loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msparse_categorical_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     59\u001B[0m         metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m     60\u001B[0m     )\n\u001B[1;32m     62\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model\n\u001B[0;32m---> 64\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mcreate_res_net\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m# or create_plain_net()\u001B[39;00m\n\u001B[1;32m     65\u001B[0m model\u001B[38;5;241m.\u001B[39msummary()\n",
      "Input \u001B[0;32mIn [2]\u001B[0m, in \u001B[0;36mcreate_res_net\u001B[0;34m()\u001B[0m\n\u001B[1;32m     45\u001B[0m     num_blocks \u001B[38;5;241m=\u001B[39m num_blocks_list[i]\n\u001B[1;32m     46\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_blocks):\n\u001B[0;32m---> 47\u001B[0m         t \u001B[38;5;241m=\u001B[39m \u001B[43mresidual_block\u001B[49m\u001B[43m(\u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdownsample\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mj\u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mand\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[38;5;241;43m!=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_filters\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     48\u001B[0m     num_filters \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[1;32m     50\u001B[0m t \u001B[38;5;241m=\u001B[39m AveragePooling2D(\u001B[38;5;241m4\u001B[39m)(t)\n",
      "Input \u001B[0;32mIn [2]\u001B[0m, in \u001B[0;36mresidual_block\u001B[0;34m(x, downsample, filters, kernel_size)\u001B[0m\n\u001B[1;32m     16\u001B[0m y \u001B[38;5;241m=\u001B[39m relu_bn(y)\n\u001B[1;32m     17\u001B[0m y \u001B[38;5;241m=\u001B[39m Conv2D(kernel_size\u001B[38;5;241m=\u001B[39mkernel_size,\n\u001B[1;32m     18\u001B[0m            strides\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m     19\u001B[0m            filters\u001B[38;5;241m=\u001B[39mfilters,\n\u001B[1;32m     20\u001B[0m            padding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msame\u001B[39m\u001B[38;5;124m\"\u001B[39m)(y)\n\u001B[0;32m---> 22\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mdownsample\u001B[49m:\n\u001B[1;32m     23\u001B[0m     x \u001B[38;5;241m=\u001B[39m Conv2D(kernel_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m     24\u001B[0m                strides\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[1;32m     25\u001B[0m                filters\u001B[38;5;241m=\u001B[39mfilters,\n\u001B[1;32m     26\u001B[0m                padding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msame\u001B[39m\u001B[38;5;124m\"\u001B[39m)(x)\n\u001B[1;32m     27\u001B[0m out \u001B[38;5;241m=\u001B[39m Add()([x, y])\n",
      "Input \u001B[0;32mIn [2]\u001B[0m, in \u001B[0;36mresidual_block\u001B[0;34m(x, downsample, filters, kernel_size)\u001B[0m\n\u001B[1;32m     16\u001B[0m y \u001B[38;5;241m=\u001B[39m relu_bn(y)\n\u001B[1;32m     17\u001B[0m y \u001B[38;5;241m=\u001B[39m Conv2D(kernel_size\u001B[38;5;241m=\u001B[39mkernel_size,\n\u001B[1;32m     18\u001B[0m            strides\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m     19\u001B[0m            filters\u001B[38;5;241m=\u001B[39mfilters,\n\u001B[1;32m     20\u001B[0m            padding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msame\u001B[39m\u001B[38;5;124m\"\u001B[39m)(y)\n\u001B[0;32m---> 22\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mdownsample\u001B[49m:\n\u001B[1;32m     23\u001B[0m     x \u001B[38;5;241m=\u001B[39m Conv2D(kernel_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m     24\u001B[0m                strides\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[1;32m     25\u001B[0m                filters\u001B[38;5;241m=\u001B[39mfilters,\n\u001B[1;32m     26\u001B[0m                padding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msame\u001B[39m\u001B[38;5;124m\"\u001B[39m)(x)\n\u001B[1;32m     27\u001B[0m out \u001B[38;5;241m=\u001B[39m Add()([x, y])\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_39_64.pyx:1179\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_39_64.SafeCallWrapper.__call__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_39_64.pyx:620\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_39_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_39_64.pyx:1095\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_39_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_39_64.pyx:1053\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_39_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/Library/Application Support/JetBrains/Toolbox/apps/DataSpell/ch-0/222.4345.24/DataSpell.app/Contents/plugins/python-ce/helpers-pro/jupyter_debug/pydev_jupyter_plugin.py:169\u001B[0m, in \u001B[0;36mstop\u001B[0;34m(plugin, pydb, frame, event, args, stop_info, arg, step_cmd)\u001B[0m\n\u001B[1;32m    167\u001B[0m     frame \u001B[38;5;241m=\u001B[39m suspend_jupyter(main_debugger, thread, frame, step_cmd)\n\u001B[1;32m    168\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m frame:\n\u001B[0;32m--> 169\u001B[0m         \u001B[43mmain_debugger\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    170\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    171\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/Library/Application Support/JetBrains/Toolbox/apps/DataSpell/ch-0/222.4345.24/DataSpell.app/Contents/plugins/python-ce/helpers/pydev/pydevd.py:1160\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1157\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[1;32m   1159\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[0;32m-> 1160\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Application Support/JetBrains/Toolbox/apps/DataSpell/ch-0/222.4345.24/DataSpell.app/Contents/plugins/python-ce/helpers/pydev/pydevd.py:1175\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1172\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[1;32m   1174\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[0;32m-> 1175\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1177\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[1;32m   1179\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow import Tensor\n",
    "from keras.layers import Input, Conv2D, ReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "def relu_bn(inputs: Tensor) -> Tensor:\n",
    "    relu = ReLU()(inputs)\n",
    "    bn = BatchNormalization()(relu)\n",
    "    return bn\n",
    "\n",
    "def residual_block(x: Tensor, downsample: bool, filters: int, kernel_size: int = 3) -> Tensor:\n",
    "    y = Conv2D(kernel_size=kernel_size,\n",
    "               strides= (1 if not downsample else 2),\n",
    "               filters=filters,\n",
    "               padding=\"same\")(x)\n",
    "    y = relu_bn(y)\n",
    "    y = Conv2D(kernel_size=kernel_size,\n",
    "               strides=1,\n",
    "               filters=filters,\n",
    "               padding=\"same\")(y)\n",
    "\n",
    "    if downsample:\n",
    "        x = Conv2D(kernel_size=1,\n",
    "                   strides=2,\n",
    "                   filters=filters,\n",
    "                   padding=\"same\")(x)\n",
    "    out = Add()([x, y])\n",
    "    out = relu_bn(out)\n",
    "    return out\n",
    "\n",
    "def create_res_net():\n",
    "\n",
    "    inputs = Input(shape=(32, 32, 3))\n",
    "    num_filters = 64\n",
    "\n",
    "    t = BatchNormalization()(inputs)\n",
    "    t = Conv2D(kernel_size=3,\n",
    "               strides=1,\n",
    "               filters=num_filters,\n",
    "               padding=\"same\")(t)\n",
    "    t = relu_bn(t)\n",
    "\n",
    "    num_blocks_list = [2, 5, 5, 2]\n",
    "    for i in range(len(num_blocks_list)):\n",
    "        num_blocks = num_blocks_list[i]\n",
    "        for j in range(num_blocks):\n",
    "            t = residual_block(t, downsample=(j==0 and i!=0), filters=num_filters)\n",
    "        num_filters *= 2\n",
    "\n",
    "    t = AveragePooling2D(4)(t)\n",
    "    t = Flatten()(t)\n",
    "    outputs = Dense(10, activation='softmax')(t)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_res_net() # or create_plain_net()\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
