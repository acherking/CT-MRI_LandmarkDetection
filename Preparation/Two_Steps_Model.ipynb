{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Check Test Dataset prediction results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "Y_pred_dir = \"/Users/achs/PhD/code/CT-MRI_LandmarkDetection/Spartan/trained_models/divided_dataset/straight_model/mean_two_landmarks/\"\n",
    "\n",
    "Y_test_pred_file = \"bestVal_straight_model_divided_176_88_48_mean_two_landmarks_MTL_p.npy\"\n",
    "# test_y_pred_file = \"bestVal_first_model_y_test.npy\"\n",
    "\n",
    "Y_test_pred_path = Y_pred_dir + Y_test_pred_file\n",
    "Y_test_pred = np.load(Y_test_pred_path)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T15:17:03.436484Z",
     "end_time": "2023-04-27T15:17:04.530420Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test Shape:  (200, 176, 176, 48)\n",
      "Y_test Shape:  (200, 4, 3)\n",
      "X_test_reshape Shape:  (200, 176, 176, 48, 1)\n",
      "Y_test Shape:  (200, 4, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-27 15:21:15.013981: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import Spartan.support_modules as supporter\n",
    "import Functions.MyDataset as MyDataset\n",
    "\n",
    "# Get the Test Dataset Prediction Results\n",
    "datasets_dir = \"/Volumes/Shawn_HDD/PhD/Project/Date/augmentation_from_matlab/Rescaled/\"\n",
    "size = (176, 176, 48)\n",
    "with_res = True\n",
    "\n",
    "str_size = str(size[0]) + \"_\" + str(size[1]) + \"_\" + str(size[2])\n",
    "if with_res:\n",
    "    str_size = str_size + \"_PD\"\n",
    "\n",
    "dataset_path = datasets_dir + str_size + \"/\"\n",
    "pat_splits = MyDataset.get_pat_splits(static=True)\n",
    "X_test, Y_test, res_test = \\\n",
    "    supporter.load_dataset(dataset_path, size, pat_splits, with_res=with_res, only_test=True)\n",
    "\n",
    "# Because the resolution is for 4 landmark points, so we repeat it to make the calculation easier.\n",
    "res_test_R4 = np.repeat(res_test, 4, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T15:20:28.042974Z",
     "end_time": "2023-04-27T15:21:15.253743Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "res_test_R4 = np.repeat(res_test, 4, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T16:32:44.062355Z",
     "end_time": "2023-04-27T16:32:44.067919Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_test_mapped Shape:  (200, 4, 3)\n",
      "Y_MTL_test_mapped Shape:  (400, 1, 3)\n"
     ]
    }
   ],
   "source": [
    "Y_test_mapped = Y_test * res_test_R4 / 0.15\n",
    "Y_MTL_test_mapped = np.mean(Y_test_mapped.reshape((400, 2, 3)), axis=1).reshape((400, 1, 3))\n",
    "# Y_test_pred_mapped = Y_test_pred * res_test_R4 / 0.15\n",
    "Y_MTL_test_mapped_pred = Y_test_pred\n",
    "\n",
    "print(\"Y_test_mapped Shape: \", Y_test_mapped.shape)\n",
    "print(\"Y_MTL_test_mapped Shape: \", Y_MTL_test_mapped.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T16:35:50.805114Z",
     "end_time": "2023-04-27T16:35:50.825269Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Check the difference between Predictions and Ground Truth"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ground Truth points and Prediction points distance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# 1. Total error distance\n",
    "# 2. Maximum one point's error distance\n",
    "# 3. If it can involve the Ground Truth points\n",
    "# 4. If it can involve the Target Area\n",
    "\n",
    "# 1. Total error distance\n",
    "err_diff = Y_MTL_test_mapped - Y_MTL_test_mapped_pred\n",
    "square_err_diff = tf.pow(err_diff, 2)\n",
    "sum_square_err_diff = tf.reduce_sum(square_err_diff, axis=[1, 2])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T16:40:25.160253Z",
     "end_time": "2023-04-27T16:40:25.178902Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min[139]: 200.25697326660156\n",
      "Max[52]: 444347.5\n",
      "Mean: 156316.28125\n"
     ]
    }
   ],
   "source": [
    "min_err_idx = np.argmin(sum_square_err_diff, axis=0)\n",
    "max_err_idx = np.argmax(sum_square_err_diff, axis=0)\n",
    "print(f\"Min[{min_err_idx}]: {sum_square_err_diff[min_err_idx]}\")\n",
    "print(f\"Max[{max_err_idx}]: {sum_square_err_diff[max_err_idx]}\")\n",
    "print(f\"Mean: {np.mean(sum_square_err_diff)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T16:40:29.270139Z",
     "end_time": "2023-04-27T16:40:29.277408Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "mu = np.mean(sum_square_err_diff)\n",
    "sigma = np.std(sum_square_err_diff)\n",
    "\n",
    "# Create the bins and histogram\n",
    "count, bins, ignored = plt.hist(sum_square_err_diff, 20)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-21T16:44:43.195068Z",
     "end_time": "2023-04-21T16:44:43.320191Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "idx = max_err_idx\n",
    "\n",
    "pat_names = MyDataset.get_pat_names()\n",
    "test_pat_idx = MyDataset.get_pat_splits(static=True)[2] # 0: train, 1: val, 2: test\n",
    "\n",
    "test_pt_idx = np.floor(idx / 50).astype(int)\n",
    "pt_aug_id = idx % 50 + 1\n",
    "\n",
    "pat_name = pat_names[test_pat_idx[test_pt_idx]]\n",
    "\n",
    "print(f\"Patient {pat_name}, Aug Id: {pt_aug_id}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-21T16:44:43.320288Z",
     "end_time": "2023-04-21T16:44:43.366099Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Check the cropped results\n",
    "import numpy as np\n",
    "import Functions.MyDataset as MyDataset\n",
    "import Functions.Visualization as Visualization\n",
    "\n",
    "aug_dir = \"/Volumes/Shawn_HDD/PhD/Project/Date/augmentation_from_matlab/original_augmentation_data/\"\n",
    "pt_aug_path = aug_dir + pat_name + \"_aug_\" + str(pt_aug_id) + \".mat\"\n",
    "\n",
    "pixel_space = [0.15, 0.15, 0.15]\n",
    "\n",
    "pt_aug_volume, pt_aug_pts, _ = MyDataset.load_mat_data(pt_aug_path)\n",
    "\n",
    "# Ground Truth\n",
    "Visualization.show_pts(pt_aug_volume, pt_aug_pts, pixel_space)\n",
    "# Prediction on original volumes\n",
    "Visualization.show_pts(pt_aug_volume, Y_test_pred_mapped[idx], pixel_space)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-21T16:44:43.324025Z",
     "end_time": "2023-04-21T16:45:25.473308Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Ground Truth\n",
    "Visualization.show_pts(X_test[idx,:,:,:,0], Y_test[idx], pixel_space)\n",
    "# Prediction\n",
    "Visualization.show_pts(X_test[idx,:,:,:,0], Y_test_pred[idx], pixel_space)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-21T16:45:25.473676Z",
     "end_time": "2023-04-21T16:45:26.533647Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ground Truth points to the Cropped Volume's border distance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import Functions.MyCrop as MyCrop\n",
    "\n",
    "# anchor = np.average(pt_aug_pts[0:2], axis=0).astype(int)\n",
    "anchor = np.average(Y_test_pred_mapped[idx][0:2], axis=0).astype(int)\n",
    "\n",
    "d = MyCrop.distance_from_border(pt_aug_volume.shape, pt_aug_pts[0:2], anchor)\n",
    "\n",
    "# attention: this is (row, column, slice) same as (y, x, z)\n",
    "print(d)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-21T16:45:26.535780Z",
     "end_time": "2023-04-21T16:45:26.538840Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-21T16:45:26.539239Z",
     "end_time": "2023-04-21T16:45:26.541581Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
