{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Check Test Dataset prediction results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import numpy as np\n",
    "\n",
    "Y_pred_dir = \"/Users/achs/PhD/code/CT-MRI_LandmarkDetection/Spartan/trained_models/divided_dataset/straight_model/mean_two_landmarks/\"\n",
    "\n",
    "Y_test_pred_file = \"bestVal_straight_model_divided_176x88x48_y_test.npy\"\n",
    "Y_test_file = \"Y_test_MTL_gt.npy\"\n",
    "# test_y_pred_file = \"bestVal_first_model_y_test.npy\"\n",
    "\n",
    "Y_test_pred_path = Y_pred_dir + Y_test_pred_file\n",
    "Y_test_pred = np.load(Y_test_pred_path)\n",
    "\n",
    "Y_test_path = Y_pred_dir + Y_test_file\n",
    "Y_test_read = np.load(Y_test_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T03:43:12.896655Z",
     "start_time": "2023-07-26T03:43:12.883964Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "res_test = np.load(f\"{Y_pred_dir}res_test.npy\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T03:43:14.257777Z",
     "start_time": "2023-07-26T03:43:14.248163Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Check the difference between Predictions and Ground Truth"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "Y_test_centre_pred_org = Y_test_pred * res_test / 0.15\n",
    "np.save(\"/Volumes/Shawn_HDD/PhD/Project/Date/bestVal_straight_model_divided_176_88_48_mean_two_landmarks_MTL_pred_org\", Y_test_centre_pred_org)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ground Truth points and Prediction points distance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 1. Total error distance\n",
    "# 2. Maximum one point's error distance\n",
    "# 3. If it can involve the Ground Truth points\n",
    "# 4. If it can involve the Target Area\n",
    "\n",
    "# 1. Total error distance\n",
    "err_diff = (Y_test_read - Y_test_pred) * res_test\n",
    "square_err_diff = tf.pow(err_diff, 2)\n",
    "sum_square_err_diff = tf.reduce_sum(square_err_diff, axis=[1, 2])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T03:47:17.313742Z",
     "start_time": "2023-07-26T03:47:17.275207Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "min_err_idx = np.argmin(sum_square_err_diff, axis=0)\n",
    "max_err_idx = np.argmax(sum_square_err_diff, axis=0)\n",
    "print(f\"Min[{min_err_idx}]: {sum_square_err_diff[min_err_idx]}\")\n",
    "print(f\"Max[{max_err_idx}]: {sum_square_err_diff[max_err_idx]}\")\n",
    "print(f\"Mean: {np.mean(sum_square_err_diff)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T03:47:31.874575Z",
     "start_time": "2023-07-26T03:47:31.833416Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "print(Y_test_read[365])\n",
    "print(Y_test_pred[365])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T03:48:23.067270Z",
     "start_time": "2023-07-26T03:48:23.046347Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "fig, axs = pyplot.subplots(2, 2, sharex=True, sharey=True, constrained_layout=True)\n",
    "\n",
    "axs[0][0].hist(sum_square_err_diff, 20)\n",
    "axs[0][0].set_xlabel(\"sum square err diff\")\n",
    "\n",
    "axs[0][1].hist(err_diff[:, 0, 0], 20)\n",
    "axs[0][1].set_xlabel(\"x: err diff\")\n",
    "\n",
    "axs[1][0].hist(err_diff[:, 0, 1], 20)\n",
    "axs[1][0].set_xlabel(\"y: err diff\")\n",
    "\n",
    "axs[1][1].hist(err_diff[:, 0, 2], 20)\n",
    "axs[1][1].set_xlabel(\"z: err diff\")\n",
    "\n",
    "pyplot.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T03:50:27.522113Z",
     "start_time": "2023-07-26T03:50:26.454103Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# create \"random\" translation value (dx, dy, dz)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "normal_bias_array = np.zeros((2000, 1, 3))\n",
    "normal_bias_array[:, 0, 0] = np.random.normal(0., 0.3, 2000)\n",
    "normal_bias_array[:, 0, 1] = np.random.normal(0., 0.3, 2000)\n",
    "normal_bias_array[:, 0, 2] = np.random.normal(0., 0.3, 2000)\n",
    "random_trans_array = np.repeat(err_diff, 5, axis=0)\n",
    "np.random.shuffle(random_trans_array)\n",
    "random_trans_array = random_trans_array + normal_bias_array"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T04:22:50.562214Z",
     "start_time": "2023-06-14T04:22:50.519860Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "np.save(\"crop_normal_bias_array\", random_trans_array)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T04:22:51.106763Z",
     "start_time": "2023-06-14T04:22:51.087955Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "random_trans_array_voxel = (random_trans_array / 0.15).astype('int')\n",
    "\n",
    "print(\"x max: \", np.max(random_trans_array_voxel[:, 0, 0]))\n",
    "print(\"x min: \", np.min(random_trans_array_voxel[:, 0, 0]))\n",
    "print(\"y max: \", np.max(random_trans_array_voxel[:, 0, 1]))\n",
    "print(\"y min: \", np.min(random_trans_array_voxel[:, 0, 1]))\n",
    "print(\"z max: \", np.max(random_trans_array_voxel[:, 0, 2]))\n",
    "print(\"z min: \", np.min(random_trans_array_voxel[:, 0, 2]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T04:23:58.733616Z",
     "start_time": "2023-06-14T04:23:58.714880Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "fig, axs = pyplot.subplots(2, 2, sharex=True, sharey=True, constrained_layout=True)\n",
    "\n",
    "# axs[0][0].hist(sum_square_err_diff, 20)\n",
    "# axs[0][0].set_xlabel(\"sum square err diff\")\n",
    "\n",
    "axs[0][1].hist(random_trans_array[:, 0, 0], 20)\n",
    "axs[0][1].set_xlabel(\"x: square err diff\")\n",
    "\n",
    "axs[1][0].hist(random_trans_array[:, 0, 1], 20)\n",
    "axs[1][0].set_xlabel(\"y: square err diff\")\n",
    "\n",
    "axs[1][1].hist(random_trans_array[:, 0, 2], 20)\n",
    "axs[1][1].set_xlabel(\"z: square err diff\")\n",
    "\n",
    "pyplot.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T06:07:32.408441Z",
     "start_time": "2023-06-14T06:07:31.849288Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import Functions.MyDataset as MyDataset\n",
    "\n",
    "idx = max_err_idx\n",
    "\n",
    "pat_names = MyDataset.get_pat_names()\n",
    "test_pat_idx = MyDataset.get_pat_splits(static=True)[2] # 0: train, 1: val, 2: test\n",
    "\n",
    "test_pt_idx = np.floor(idx / 100).astype(int)\n",
    "pt_aug_id = np.floor(idx % 100 / 2).astype(int) + 1\n",
    "\n",
    "pat_name = pat_names[test_pat_idx[test_pt_idx]]\n",
    "\n",
    "print(f\"Patient {pat_name}, Aug Id: {pt_aug_id}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T01:43:29.821592Z",
     "start_time": "2023-06-14T01:43:29.797922Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "## Check the cropped results\n",
    "import numpy as np\n",
    "import Functions.MyDataset as MyDataset\n",
    "import Functions.Visualization as Visualization\n",
    "\n",
    "import importlib\n",
    "\n",
    "importlib.reload(Visualization)\n",
    "\n",
    "aug_dir = \"/Volumes/Shawn_HDD/PhD/Project/Date/augmentation_from_matlab/original_augmentation_data/\"\n",
    "pt_aug_path = aug_dir + pat_name + \"_aug_\" + str(pt_aug_id) + \".mat\"\n",
    "\n",
    "pixel_space = [0.15, 0.15, 0.15]\n",
    "\n",
    "pt_aug_volume, pt_aug_pts, _ = MyDataset.load_mat_data(pt_aug_path)\n",
    "\n",
    "# # Ground Truth\n",
    "#\n",
    "# Visualization.show_two_centres(pt_aug_volume, pt_left_centre, pt_right_centre, pixel_space)\n",
    "# # Prediction on original volumes\n",
    "# Visualization.show_two_centres(pt_aug_volume, , , pixel_space)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-13T14:06:13.795284Z",
     "end_time": "2023-06-13T14:06:50.356145Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "importlib.reload(Visualization)\n",
    "\n",
    "# Ground Truth\n",
    "centres = np.mean(pt_aug_pts.reshape((2,2,3)), axis=1)\n",
    "\n",
    "Visualization.show_two_centres(pt_aug_volume, centres, pixel_space)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-13T14:07:41.186547Z",
     "end_time": "2023-06-13T14:07:43.742304Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Prediction on original volumes\n",
    "Y_test_pred_org = Y_test_pred * res_test / 0.15\n",
    "Visualization.show_two_centres(pt_aug_volume, np.squeeze(Y_test_pred_org[[160,161]]), pixel_space)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-13T14:08:15.259689Z",
     "end_time": "2023-06-13T14:08:17.636922Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ground Truth points to the Cropped Volume's border distance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "import Functions.MyCrop as MyCrop\n",
    "\n",
    "anchor = centres[1]\n",
    "anchor_pred = Y_test_pred_org[idx, 0]\n",
    "\n",
    "crop_s = ((45, 45), (45, 45), (45, 45))\n",
    "d = MyCrop.distance_from_border(pt_aug_volume.shape, pt_aug_pts[2:4], anchor, crop_size=crop_s)\n",
    "d_pred = MyCrop.distance_from_border(pt_aug_volume.shape, pt_aug_pts[2:4], anchor_pred, crop_size=crop_s)\n",
    "\n",
    "# attention: this is (row, column, slice) same as (y, x, z)\n",
    "print(\"Based on Ground Truth: \", d)\n",
    "print(\"Based on Prediction: \", d_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-13T14:09:53.236856Z",
     "end_time": "2023-06-13T14:09:53.282134Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# show ground truth cropped volume\n",
    "importlib.reload(Visualization)\n",
    "\n",
    "left_area, left_landmarks, left_cropped_length, \\\n",
    "    right_area, right_landmarks, right_cropped_length = MyCrop.crop_volume(pt_aug_volume, pt_aug_pts)\n",
    "\n",
    "left_centre = np.mean(left_landmarks, axis=0).reshape(1,3)\n",
    "right_centre = np.mean(right_landmarks, axis=0).reshape(1,3)\n",
    "centres_cropped = np.concatenate((left_centre, right_centre), axis=0)\n",
    "Visualization.show_two_centres_cropped(left_area, right_area, centres_cropped, pixel_space)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-13T14:15:07.867997Z",
     "end_time": "2023-06-13T14:15:12.533847Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# for convenient...\n",
    "centres_pred_r2 = np.repeat(Y_test_pred_org[[160, 161]], 2, axis=1).reshape(4,3)\n",
    "print(centres_pred_r2.shape)\n",
    "print(centres_pred_r2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-13T14:17:03.042194Z",
     "end_time": "2023-06-13T14:17:03.096255Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# show prediction cropped volume\n",
    "left_area_pred, left_landmarks_pred, left_cropped_length_pred, \\\n",
    "    right_area_pred, right_landmarks_pred, right_cropped_length_pred \\\n",
    "    = MyCrop.crop_volume(pt_aug_volume, centres_pred_r2)\n",
    "\n",
    "left_centre_pred = np.mean(left_landmarks_pred, axis=0).reshape(1,3)\n",
    "right_centre_pred = np.mean(right_landmarks_pred, axis=0).reshape(1,3)\n",
    "centres_cropped_pred = np.concatenate((left_centre_pred, right_centre_pred), axis=0)\n",
    "Visualization.show_two_centres_cropped(left_area_pred, right_area_pred, centres_cropped_pred, pixel_space)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-13T14:17:04.883360Z",
     "end_time": "2023-06-13T14:17:06.613754Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
