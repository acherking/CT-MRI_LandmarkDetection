{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Check Test Dataset prediction results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "Y_pred_dir = \"/Users/achs/PhD/code/CT-MRI_LandmarkDetection/Spartan/trained_models/divided_dataset/straight_model/mean_two_landmarks/\"\n",
    "\n",
    "Y_test_pred_file = \"bestVal_straight_model_divided_176_88_48_mean_two_landmarks_MTL_p.npy\"\n",
    "Y_test_file = \"bestVal_straight_model_divided_176_88_48_mean_two_landmarks_MTL.npy\"\n",
    "# test_y_pred_file = \"bestVal_first_model_y_test.npy\"\n",
    "\n",
    "Y_test_pred_path = Y_pred_dir + Y_test_pred_file\n",
    "Y_test_pred = np.load(Y_test_pred_path)\n",
    "\n",
    "Y_test_path = Y_pred_dir + Y_test_file\n",
    "Y_test_read = np.load(Y_test_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-09T15:52:58.512307Z",
     "end_time": "2023-05-09T15:52:59.940739Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import Spartan.support_modules as supporter\n",
    "import Functions.MyDataset as MyDataset\n",
    "\n",
    "# Get the Test Dataset Prediction Results\n",
    "datasets_dir = \"/Volumes/Shawn_HDD/PhD/Project/Date/augmentation_from_matlab/Rescaled/\"\n",
    "size = (176, 176, 48)\n",
    "with_res = True\n",
    "\n",
    "str_size = str(size[0]) + \"_\" + str(size[1]) + \"_\" + str(size[2])\n",
    "if with_res:\n",
    "    str_size = str_size + \"_PD\"\n",
    "\n",
    "dataset_path = datasets_dir + str_size + \"/\"\n",
    "pat_splits = MyDataset.get_pat_splits(static=True)\n",
    "X_test, Y_test, res_test = \\\n",
    "    supporter.load_dataset(dataset_path, size, pat_splits, with_res=with_res, only_test=True)\n",
    "\n",
    "# Because the resolution is for 4 landmark points, so we repeat it to make the calculation easier.\n",
    "res_test_R2 = np.repeat(res_test, 2, axis=1)\n",
    "res_test_R2 = res_test_R2.reshape(400, 1, 3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-09T15:53:03.147946Z",
     "end_time": "2023-05-09T15:53:56.290354Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Y_test_mapped = Y_test * res_test_R4 / 0.15\n",
    "# Y_MTL_test_mapped = np.mean(Y_test_mapped.reshape((400, 2, 3)), axis=1).reshape((400, 1, 3))\n",
    "Y_MTL_test = np.mean(Y_test.reshape((400, 2, 3)), axis=1).reshape((400, 1, 3))\n",
    "\n",
    "print(\"Y_MTL_test Shape: \", Y_MTL_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-09T15:54:01.479184Z",
     "end_time": "2023-05-09T15:54:01.490035Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Check the difference between Predictions and Ground Truth"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Y_test_centre_pred_org = Y_test_pred * res_test_R2 / 0.15\n",
    "np.save(\"/Volumes/Shawn_HDD/PhD/Project/Date/bestVal_straight_model_divided_176_88_48_mean_two_landmarks_MTL_pred_org\", Y_test_centre_pred_org)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-09T15:54:20.307725Z",
     "end_time": "2023-05-09T15:54:20.677095Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ground Truth points and Prediction points distance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1. Total error distance\n",
    "# 2. Maximum one point's error distance\n",
    "# 3. If it can involve the Ground Truth points\n",
    "# 4. If it can involve the Target Area\n",
    "\n",
    "# 1. Total error distance\n",
    "err_diff = (Y_MTL_test - Y_test_pred) * res_test_R2\n",
    "square_err_diff = tf.pow(err_diff, 2)\n",
    "sum_square_err_diff = tf.reduce_sum(square_err_diff, axis=[1, 2])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-09T15:54:22.883080Z",
     "end_time": "2023-05-09T15:54:22.901534Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "min_err_idx = np.argmin(sum_square_err_diff, axis=0)\n",
    "max_err_idx = np.argmax(sum_square_err_diff, axis=0)\n",
    "print(f\"Min[{min_err_idx}]: {sum_square_err_diff[min_err_idx]}\")\n",
    "print(f\"Max[{max_err_idx}]: {sum_square_err_diff[max_err_idx]}\")\n",
    "print(f\"Mean: {np.mean(sum_square_err_diff)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-09T15:54:23.813503Z",
     "end_time": "2023-05-09T15:54:23.821644Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(Y_MTL_test[161])\n",
    "print(Y_test_pred[161])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-09T15:54:25.341625Z",
     "end_time": "2023-05-09T15:54:25.348918Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "mu = np.mean(sum_square_err_diff)\n",
    "sigma = np.std(sum_square_err_diff)\n",
    "\n",
    "# Create the bins and histogram\n",
    "count, bins, ignored = plt.hist(sum_square_err_diff, 20)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-09T15:54:26.860115Z",
     "end_time": "2023-05-09T15:54:28.400459Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "idx = max_err_idx\n",
    "\n",
    "pat_names = MyDataset.get_pat_names()\n",
    "test_pat_idx = MyDataset.get_pat_splits(static=True)[2] # 0: train, 1: val, 2: test\n",
    "\n",
    "test_pt_idx = np.floor(idx / 100).astype(int)\n",
    "pt_aug_id = np.floor(idx % 100 / 2).astype(int) + 1\n",
    "\n",
    "pat_name = pat_names[test_pat_idx[test_pt_idx]]\n",
    "\n",
    "print(f\"Patient {pat_name}, Aug Id: {pt_aug_id}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-09T15:54:32.470086Z",
     "end_time": "2023-05-09T15:54:32.500776Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Check the cropped results\n",
    "import numpy as np\n",
    "import Functions.MyDataset as MyDataset\n",
    "import Functions.Visualization as Visualization\n",
    "\n",
    "import importlib\n",
    "\n",
    "importlib.reload(Visualization)\n",
    "\n",
    "aug_dir = \"/Volumes/Shawn_HDD/PhD/Project/Date/augmentation_from_matlab/original_augmentation_data/\"\n",
    "pt_aug_path = aug_dir + pat_name + \"_aug_\" + str(pt_aug_id) + \".mat\"\n",
    "\n",
    "pixel_space = [0.15, 0.15, 0.15]\n",
    "\n",
    "pt_aug_volume, pt_aug_pts, _ = MyDataset.load_mat_data(pt_aug_path)\n",
    "\n",
    "# # Ground Truth\n",
    "#\n",
    "# Visualization.show_two_centres(pt_aug_volume, pt_left_centre, pt_right_centre, pixel_space)\n",
    "# # Prediction on original volumes\n",
    "# Visualization.show_two_centres(pt_aug_volume, , , pixel_space)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-09T15:54:55.899170Z",
     "end_time": "2023-05-09T15:55:37.423025Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "importlib.reload(Visualization)\n",
    "\n",
    "# Ground Truth\n",
    "centres = np.mean(pt_aug_pts.reshape((2,2,3)), axis=1)\n",
    "\n",
    "Visualization.show_two_centres(pt_aug_volume, centres, pixel_space)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-09T15:56:03.316702Z",
     "end_time": "2023-05-09T15:56:05.644919Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Prediction on original volumes\n",
    "Y_test_pred_org = Y_test_pred * res_test_R2 / 0.15\n",
    "Visualization.show_two_centres(pt_aug_volume, np.squeeze(Y_test_pred_org[[160,161]]), pixel_space)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-09T15:56:13.277783Z",
     "end_time": "2023-05-09T15:56:15.583796Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ground Truth points to the Cropped Volume's border distance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import Functions.MyCrop as MyCrop\n",
    "\n",
    "anchor = centres[1]\n",
    "anchor_pred = Y_test_pred_org[idx, 0]\n",
    "\n",
    "crop_s = ((45, 45), (45, 45), (45, 45))\n",
    "d = MyCrop.distance_from_border(pt_aug_volume.shape, pt_aug_pts[2:4], anchor, crop_size=crop_s)\n",
    "d_pred = MyCrop.distance_from_border(pt_aug_volume.shape, pt_aug_pts[2:4], anchor_pred, crop_size=crop_s)\n",
    "\n",
    "# attention: this is (row, column, slice) same as (y, x, z)\n",
    "print(\"Based on Ground Truth: \", d)\n",
    "print(\"Based on Prediction: \", d_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-09T15:58:06.041723Z",
     "end_time": "2023-05-09T15:58:06.067482Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# show ground truth cropped volume\n",
    "importlib.reload(Visualization)\n",
    "\n",
    "left_area, left_landmarks, left_cropped_length, \\\n",
    "    right_area, right_landmarks, right_cropped_length = MyCrop.crop_volume(pt_aug_volume, pt_aug_pts)\n",
    "\n",
    "left_centre = np.mean(left_landmarks, axis=0).reshape(1,3)\n",
    "right_centre = np.mean(right_landmarks, axis=0).reshape(1,3)\n",
    "centres_cropped = np.concatenate((left_centre, right_centre), axis=0)\n",
    "Visualization.show_two_centres_cropped(left_area, right_area, centres_cropped, pixel_space)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T16:58:39.161091Z",
     "end_time": "2023-05-01T16:58:40.799418Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for convenient...\n",
    "centres_pred_r2 = np.repeat(Y_test_pred_org[[160, 161]], 2, axis=1).reshape(4,3)\n",
    "print(centres_pred_r2.shape)\n",
    "print(centres_pred_r2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T17:02:19.702731Z",
     "end_time": "2023-05-01T17:02:19.718333Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# show prediction cropped volume\n",
    "left_area_pred, left_landmarks_pred, left_cropped_length_pred, \\\n",
    "    right_area_pred, right_landmarks_pred, right_cropped_length_pred \\\n",
    "    = MyCrop.crop_volume(pt_aug_volume, centres_pred_r2)\n",
    "\n",
    "left_centre_pred = np.mean(left_landmarks_pred, axis=0).reshape(1,3)\n",
    "right_centre_pred = np.mean(right_landmarks_pred, axis=0).reshape(1,3)\n",
    "centres_cropped_pred = np.concatenate((left_centre_pred, right_centre_pred), axis=0)\n",
    "Visualization.show_two_centres_cropped(left_area_pred, right_area_pred, centres_cropped_pred, pixel_space)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T17:03:33.923872Z",
     "end_time": "2023-05-01T17:03:35.406843Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
