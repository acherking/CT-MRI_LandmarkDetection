sinteractive -p gpu-a100 --gres=gpu:1 -A ***
# sinteractive -p gpu-a100 --gres=gpu:1 --mem=30G --time=(01:30:00?)


-p: partition
--gres: generic resources
-A: account group, e.g.punim0006
--time 00:05:00


module purge
module load CUDA/11.7.0
module load TensorFlow/2.11.0-CUDA-11.7.0
 

# It seems this version was not compiled to use GPU
module load tensorflow/2.7.1

***Slurm***
# Slurm Environmental Variables
https://hpcc.umd.edu/hpcc/help/slurmenv.html

scontrol write batch_script <job_id>

***Python***

import tensorflow as tf
print("Num GPUs Available: ", len(tf.config.list_physical_devices('GPU')))


# To show which device dit the operations
tf.debugging.set_log_device_placement(True)

# Data Parallelism basics?
## 1. divide batch: batch-size=10, 2 GPUs, each batch of size 10 will be divided among the 2 GPUs, with each receiving 5 input examples in each step.

*** Conda 
# activate Env
. /Users/achs/opt/anaconda3/bin/activate && conda activate /Users/achs/opt/anaconda3/envs/test;

*** Python crop and combine
import support_modules
import numpy as np

base_dir = "/data/gpfs/projects/punim1836/Data/cropped/based_on_truth/x100100y100100z8080"

x_dir = base_dir + "/volumes/"

y_dir = base_dir + "/points/"

length_dir = base_dir + "/length/"

import support_modules

support_modules.load_dataset_crop_dir(x_dir,y_dir,length_dir)

import importlib

importlib.reload(support_modules)

*** Python tmp


