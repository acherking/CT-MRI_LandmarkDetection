{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-05T00:22:55.074681Z",
     "start_time": "2024-07-05T00:22:47.509659Z"
    }
   },
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(\n",
    "        layers.Dense(\n",
    "            # Define the hyperparameter.\n",
    "            units=hp.Int(\"units\", min_value=32, max_value=512, step=32),\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "    )\n",
    "    model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T00:22:59.958049Z",
     "start_time": "2024-07-05T00:22:58.149766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import keras_tuner\n",
    "\n",
    "build_model(keras_tuner.HyperParameters())"
   ],
   "id": "330f66f9433db2a0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-05 10:22:59.757229: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7fe513f07160>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T00:34:43.955426Z",
     "start_time": "2024-07-05T00:34:43.947249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hp = keras_tuner.HyperParameters()\n",
    "print(hp.Int(\"units\", min_value=32, max_value=512, step=32))\n",
    "\n",
    "# always the same"
   ],
   "id": "414df48fefaa34bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T00:36:52.011239Z",
     "start_time": "2024-07-05T00:36:51.987810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def call_existing_code(units, activation, dropout, lr):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(units=units, activation=activation))\n",
    "    if dropout:\n",
    "        model.add(layers.Dropout(rate=0.25))\n",
    "    model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_model(hp):\n",
    "    units = hp.Int(\"units\", min_value=32, max_value=512, step=32)\n",
    "    activation = hp.Choice(\"activation\", [\"relu\", \"tanh\"])\n",
    "    dropout = hp.Boolean(\"dropout\")\n",
    "    lr = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "    # call existing model-building code with the hyperparameter values.\n",
    "    model = call_existing_code(\n",
    "        units=units, activation=activation, dropout=dropout, lr=lr\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "build_model(keras_tuner.HyperParameters())"
   ],
   "id": "b7c1b17f03768801",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7fe5150bdb50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T00:42:05.445826Z",
     "start_time": "2024-07-05T00:42:05.389567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Flatten())\n",
    "    # Tune the number of layers.\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 3)):\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "                # Tune number of units separately.\n",
    "                units=hp.Int(f\"units_{i}\", min_value=32, max_value=512, step=32),\n",
    "                activation=hp.Choice(\"activation\", [\"relu\", \"tanh\"]),\n",
    "            )\n",
    "        )\n",
    "    if hp.Boolean(\"dropout\"):\n",
    "        model.add(layers.Dropout(rate=0.25))\n",
    "    model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "    learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "build_model(keras_tuner.HyperParameters())"
   ],
   "id": "e2600c23b1ec0242",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7fe5147cf340>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T00:49:34.880548Z",
     "start_time": "2024-07-05T00:49:34.778080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tuner = keras_tuner.RandomSearch(\n",
    "    hypermodel=build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=3,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"helloworld\",\n",
    ")"
   ],
   "id": "20cdc18099e4f18c",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T00:49:40.066474Z",
     "start_time": "2024-07-05T00:49:40.059390Z"
    }
   },
   "cell_type": "code",
   "source": "tuner.search_space_summary()",
   "id": "6a9b9a170a25070a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 5\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 3, 'step': 1, 'sampling': 'linear'}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "activation (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh'], 'ordered': False}\n",
      "dropout (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "lr (Float)\n",
      "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T00:50:29.552641Z",
     "start_time": "2024-07-05T00:50:28.892517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "(x, y), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x[:-10000]\n",
    "x_val = x[-10000:]\n",
    "y_train = y[:-10000]\n",
    "y_val = y[-10000:]\n",
    "\n",
    "x_train = np.expand_dims(x_train, -1).astype(\"float32\") / 255.0\n",
    "x_val = np.expand_dims(x_val, -1).astype(\"float32\") / 255.0\n",
    "x_test = np.expand_dims(x_test, -1).astype(\"float32\") / 255.0\n",
    "\n",
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ],
   "id": "f167aa5c682210cf",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tuner.search(x_train, y_train, epochs=2, validation_data=(x_val, y_val))",
   "id": "49709e5f88ad57bb",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 00m 20s]\n",
      "val_accuracy: 0.9187000095844269\n",
      "\n",
      "Best val_accuracy So Far: 0.9552499949932098\n",
      "Total elapsed time: 00h 01m 03s\n"
     ]
    }
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T01:26:31.497321Z",
     "start_time": "2024-07-05T01:26:30.045538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "models = tuner.get_best_models(num_models=2)\n",
    "best_model = models[0]\n",
    "\n",
    "best_model.predict(x_val)"
   ],
   "id": "515ac1b0da72f435",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T01:28:06.955243Z",
     "start_time": "2024-07-05T01:28:06.935714Z"
    }
   },
   "cell_type": "code",
   "source": "best_model.summary()",
   "id": "ee96843ca8137b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 160)               125600    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                5152      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 131,082\n",
      "Trainable params: 131,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T01:09:36.346886Z",
     "start_time": "2024-07-05T01:09:36.341052Z"
    }
   },
   "cell_type": "code",
   "source": "tuner.results_summary()",
   "id": "c5bf4f14c27d8d43",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in my_dir/helloworld\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 1 summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 160\n",
      "activation: tanh\n",
      "dropout: False\n",
      "lr: 0.00035910093218825\n",
      "units_1: 32\n",
      "Score: 0.9552499949932098\n",
      "\n",
      "Trial 0 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 32\n",
      "activation: tanh\n",
      "dropout: True\n",
      "lr: 0.0044752893389945645\n",
      "Score: 0.9430499970912933\n",
      "\n",
      "Trial 2 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 32\n",
      "activation: relu\n",
      "dropout: False\n",
      "lr: 0.00015596159477600306\n",
      "units_1: 128\n",
      "Score: 0.9187000095844269\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T01:41:04.676973Z",
     "start_time": "2024-07-05T01:40:57.009728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get the top 2 hyperparameters.\n",
    "best_hps = tuner.get_best_hyperparameters(5)\n",
    "# Build the model with the best hp.\n",
    "model = build_model(best_hps[0])\n",
    "# Fit with the entire dataset.\n",
    "x_all = np.concatenate((x_train, x_val))\n",
    "y_all = np.concatenate((y_train, y_val))\n",
    "model.fit(x=x_all, y=y_all, epochs=1)"
   ],
   "id": "3d3678e55ea8ddf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3744 - accuracy: 0.9011\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe4e9b67a60>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T01:47:36.426175Z",
     "start_time": "2024-07-05T01:47:34.869458Z"
    }
   },
   "cell_type": "code",
   "source": "model.evaluate(x_test, y_test)",
   "id": "7ea59305c26ebb3e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2146 - accuracy: 0.9403\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.21456469595432281, 0.9402999877929688]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T02:25:17.271122Z",
     "start_time": "2024-07-05T02:25:17.261187Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MyHyperModel(keras_tuner.HyperModel):\n",
    "    def build(self, hp):\n",
    "        model = keras.Sequential()\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "                units=hp.Int(\"units\", min_value=32, max_value=512, step=32),\n",
    "                activation=\"relu\",\n",
    "            )\n",
    "        )\n",
    "        model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "        model.compile(\n",
    "            optimizer=\"adam\",\n",
    "            loss=\"categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\"],\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    def fit(self, hp, model, *args, **kwargs):\n",
    "        return model.fit(\n",
    "            *args,\n",
    "            # Tune whether to shuffle the data in each epoch.\n",
    "            shuffle=hp.Boolean(\"shuffle\"),\n",
    "            **kwargs,\n",
    "        )"
   ],
   "id": "9ad8f64767721bee",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T02:25:54.043844Z",
     "start_time": "2024-07-05T02:25:53.446022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hp = keras_tuner.HyperParameters()\n",
    "hypermodel = MyHyperModel()\n",
    "model = hypermodel.build(hp)\n",
    "hypermodel.fit(hp, model, np.random.rand(100, 28, 28), np.random.rand(100, 10))"
   ],
   "id": "9de99e15e2d91a52",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step - loss: 11.8931 - accuracy: 0.0600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe4e7bd6b50>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T03:48:51.968498Z",
     "start_time": "2024-07-05T03:48:51.026876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MyHyperModel(keras_tuner.HyperModel):\n",
    "    def build(self, hp):\n",
    "        model = keras.Sequential()\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "                units=hp.Int(\"units\", min_value=32, max_value=512, step=32),\n",
    "                activation=\"relu\",\n",
    "            )\n",
    "        )\n",
    "        model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "        model.compile(\n",
    "            optimizer=\"adam\",\n",
    "            loss=\"categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\"],\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    def fit(self, hp, model, x, y, **kwargs):\n",
    "        if hp.Boolean(\"normalize\"):\n",
    "            x = layers.Normalization()(x)\n",
    "        return model.fit(\n",
    "            x,\n",
    "            y,\n",
    "            # Tune whether to shuffle the data in each epoch.\n",
    "            shuffle=hp.Boolean(\"shuffle\"),\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "\n",
    "hp = keras_tuner.HyperParameters()\n",
    "hypermodel = MyHyperModel()\n",
    "model = hypermodel.build(hp)\n",
    "hypermodel.fit(hp, model, np.random.rand(100, 28, 28), np.random.rand(100, 10))"
   ],
   "id": "f6b393f5bc6c1098",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 8ms/step - loss: 13.5236 - accuracy: 0.1100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe4e82cccd0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class MyHyperModel(keras_tuner.HyperModel):\n",
    "    def build(self, hp):\n",
    "        image_size = hp.Int(\"image_size\", 10, 28)\n",
    "        inputs = keras.Input(shape=(image_size, image_size))\n",
    "        outputs = layers.Flatten()(inputs)\n",
    "        outputs = layers.Dense(\n",
    "            units=hp.Int(\"units\", min_value=32, max_value=512, step=32),\n",
    "            activation=\"relu\",\n",
    "        )(outputs)\n",
    "        outputs = layers.Dense(10, activation=\"softmax\")(outputs)\n",
    "        model = keras.Model(inputs, outputs)\n",
    "        model.compile(\n",
    "            optimizer=\"adam\",\n",
    "            loss=\"categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\"],\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    def fit(self, hp, model, x, y, validation_data=None, **kwargs):\n",
    "        if hp.Boolean(\"normalize\"):\n",
    "            x = layers.Normalization()(x)\n",
    "        image_size = hp.get(\"image_size\")\n",
    "        cropped_x = x[:, :image_size, :image_size, :]\n",
    "        if validation_data:\n",
    "            x_val, y_val = validation_data\n",
    "            cropped_x_val = x_val[:, :image_size, :image_size, :]\n",
    "            validation_data = (cropped_x_val, y_val)\n",
    "        return model.fit(\n",
    "            cropped_x,\n",
    "            y,\n",
    "            # Tune whether to shuffle the data in each epoch.\n",
    "            shuffle=hp.Boolean(\"shuffle\"),\n",
    "            validation_data=validation_data,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "\n",
    "tuner = keras_tuner.RandomSearch(\n",
    "    MyHyperModel(),\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=3,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"tune_hypermodel\",\n",
    ")\n",
    "\n",
    "tuner.search(x_train, y_train, epochs=2, validation_data=(x_val, y_val))"
   ],
   "id": "dcb4b197519f50",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 00m 14s]\n",
      "val_accuracy: 0.972599983215332\n",
      "\n",
      "Best val_accuracy So Far: 0.972599983215332\n",
      "Total elapsed time: 00h 00m 50s\n"
     ]
    }
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T04:00:56.221339Z",
     "start_time": "2024-07-05T04:00:48.684791Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hypermodel = MyHyperModel()\n",
    "best_hp = tuner.get_best_hyperparameters()[0]\n",
    "model = hypermodel.build(best_hp)\n",
    "hypermodel.fit(best_hp, model, x_all, y_all, epochs=1)"
   ],
   "id": "677b6833fa270ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2123 - accuracy: 0.9374\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe4dfdd6fd0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def build_regressor(hp):\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            layers.Dense(units=hp.Int(\"units\", 32, 128, 32), activation=\"relu\"),\n",
    "            layers.Dense(units=1),\n",
    "        ]\n",
    "    )\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"mean_squared_error\",\n",
    "        # Objective is one of the metrics.\n",
    "        metrics=[keras.metrics.MeanAbsoluteError()],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "tuner = keras_tuner.RandomSearch(\n",
    "    hypermodel=build_regressor,\n",
    "    # The objective name and direction.\n",
    "    # Name is the f\"val_{snake_case_metric_class_name}\".\n",
    "    objective=keras_tuner.Objective(\"val_mean_absolute_error\", direction=\"min\"),\n",
    "    max_trials=3,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"built_in_metrics\",\n",
    ")\n",
    "\n",
    "tuner.search(\n",
    "    x=np.random.rand(100, 10),\n",
    "    y=np.random.rand(100, 1),\n",
    "    validation_data=(np.random.rand(20, 10), np.random.rand(20, 1)),\n",
    ")\n",
    "\n",
    "tuner.results_summary()"
   ],
   "id": "e342b854025ce867",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 00m 01s]\n",
      "val_mean_absolute_error: 0.26062503457069397\n",
      "\n",
      "Best val_mean_absolute_error So Far: 0.26062503457069397\n",
      "Total elapsed time: 00h 00m 03s\n",
      "Results summary\n",
      "Results in my_dir/built_in_metrics\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_mean_absolute_error\", direction=\"min\")\n",
      "\n",
      "Trial 2 summary\n",
      "Hyperparameters:\n",
      "units: 32\n",
      "Score: 0.26062503457069397\n",
      "\n",
      "Trial 0 summary\n",
      "Hyperparameters:\n",
      "units: 96\n",
      "Score: 0.264942467212677\n",
      "\n",
      "Trial 1 summary\n",
      "Hyperparameters:\n",
      "units: 64\n",
      "Score: 0.2928164005279541\n"
     ]
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class MyTuner(keras_tuner.RandomSearch):\n",
    "    def run_trial(self, trial, *args, **kwargs):\n",
    "        # Get the hp from trial.\n",
    "        hp = trial.hyperparameters\n",
    "        # Define \"x\" as a hyperparameter.\n",
    "        x = hp.Float(\"x\", min_value=-1.0, max_value=1.0)\n",
    "        # Return the objective value to minimize.\n",
    "        return x * x + 1\n",
    "\n",
    "\n",
    "tuner = MyTuner(\n",
    "    # No hypermodel or objective specified.\n",
    "    max_trials=20,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"tune_anything\",\n",
    ")\n",
    "\n",
    "# No need to pass anything to search()\n",
    "# unless you use them in run_trial().\n",
    "tuner.search()\n",
    "print(tuner.get_best_hyperparameters()[0].get(\"x\"))"
   ],
   "id": "205187904989e00d",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 00m 00s]\n",
      "default_objective: 1.1936704327299446\n",
      "\n",
      "Best default_objective So Far: 1.0133355168781635\n",
      "Total elapsed time: 00h 00m 00s\n",
      "-0.11547950847732014\n"
     ]
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def keras_code(units, optimizer, saving_path):\n",
    "    # Build model\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            layers.Dense(units=units, activation=\"relu\"),\n",
    "            layers.Dense(units=1),\n",
    "        ]\n",
    "    )\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"mean_squared_error\",\n",
    "    )\n",
    "\n",
    "    # Prepare data\n",
    "    x_train = np.random.rand(100, 10)\n",
    "    y_train = np.random.rand(100, 1)\n",
    "    x_val = np.random.rand(20, 10)\n",
    "    y_val = np.random.rand(20, 1)\n",
    "\n",
    "    # Train & eval model\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # Save model\n",
    "    model.save(saving_path)\n",
    "\n",
    "    # Return a single float as the objective value.\n",
    "    # You may also return a dictionary\n",
    "    # of {metric_name: metric_value}.\n",
    "    y_pred = model.predict(x_val)\n",
    "    return np.mean(np.abs(y_pred - y_val))\n",
    "\n",
    "\n",
    "class MyTuner(keras_tuner.RandomSearch):\n",
    "    def run_trial(self, trial, **kwargs):\n",
    "        hp = trial.hyperparameters\n",
    "        return keras_code(\n",
    "            units=hp.Int(\"units\", 32, 128, 32),\n",
    "            optimizer=hp.Choice(\"optimizer\", [\"adam\", \"adadelta\"]),\n",
    "            saving_path=os.path.join(\"/tmp\", f\"{trial.trial_id}.keras\"),\n",
    "        )\n",
    "\n",
    "\n",
    "tuner = MyTuner(\n",
    "    max_trials=3,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"keep_code_separate\",\n",
    ")\n",
    "tuner.search()\n",
    "# Retraining the model\n",
    "best_hp = tuner.get_best_hyperparameters()[0]\n",
    "# keras_code(**best_hp.values, saving_path=\"/tmp/best_model.keras\")"
   ],
   "id": "7c3d8e2239c0db99",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 00m 00s]\n",
      "default_objective: 0.6221386297148477\n",
      "\n",
      "Best default_objective So Far: 0.27175774912643547\n",
      "Total elapsed time: 00h 00m 02s\n"
     ]
    }
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T04:53:59.948361Z",
     "start_time": "2024-07-05T04:53:59.944442Z"
    }
   },
   "cell_type": "code",
   "source": "bv = best_hp.values",
   "id": "e467aa72395b60f6",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a83f0a8e6cf9733"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
