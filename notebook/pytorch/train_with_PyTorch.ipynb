{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a46b55b5-c5ea-4fc2-912f-598c29942e93",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b335dfc5-76af-4c75-aeec-8080058dc7de",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_dataset_divide(dataset_dir, rescaled_size, idx_splits, no_split=False):\n",
    "    size_str = f\"{rescaled_size[0]}{rescaled_size[1]}{rescaled_size[2]}\"\n",
    "\n",
    "    x_dataset_path = dataset_dir + \"divided_volumes_\" + size_str + \".npy\"\n",
    "    y_dataset_path = dataset_dir + \"divided_points_\" + size_str + \".npy\"\n",
    "    res_dataset_path = dataset_dir + \"divided_res_\" + size_str + \".npy\"\n",
    "\n",
    "    x_dataset = np.load(x_dataset_path).astype('float32')\n",
    "    y_dataset = np.load(y_dataset_path).astype('float32')\n",
    "    res_dataset = np.load(res_dataset_path).astype('float32')\n",
    "\n",
    "    res_dataset_rep = np.repeat(res_dataset, 2, axis=1).reshape(2000, 1, 3)\n",
    "\n",
    "    # without splitting to Train, Val and Test\n",
    "    if no_split:\n",
    "        return x_dataset, y_dataset, res_dataset_rep\n",
    "\n",
    "    train_idx = idx_splits[0]\n",
    "    x_train = x_dataset[train_idx]\n",
    "    y_train = y_dataset[train_idx]\n",
    "    res_train = res_dataset_rep[train_idx]\n",
    "\n",
    "    val_idx = idx_splits[1]\n",
    "    x_val = x_dataset[val_idx]\n",
    "    y_val = y_dataset[val_idx]\n",
    "    res_val = res_dataset_rep[val_idx]\n",
    "\n",
    "    test_idx = idx_splits[2]\n",
    "    x_test = x_dataset[test_idx]\n",
    "    y_test = y_dataset[test_idx]\n",
    "    res_test = res_dataset_rep[test_idx]\n",
    "\n",
    "    return x_train, y_train, res_train, \\\n",
    "        x_val, y_val, res_val, \\\n",
    "        x_test, y_test, res_test"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9e29f01-7a84-452e-a9ab-da1eeb7788e0",
   "metadata": {},
   "source": [
    "def get_data_splits(pat_splits, split=False, aug_num=50):\n",
    "\n",
    "    if split:\n",
    "        double_aug_num = aug_num * 2\n",
    "        idx_splits = [[list(range(i * double_aug_num, i * double_aug_num + double_aug_num)) for i in j] for j in pat_splits]\n",
    "        for i in range(0, 3):\n",
    "            idx_splits[i] = [num for sublist in idx_splits[i] for num in sublist]\n",
    "            idx_splits[i] = np.asarray(idx_splits[i])\n",
    "    else:\n",
    "        idx_splits = [[list(range(i * aug_num, i * aug_num + aug_num)) for i in j] for j in pat_splits]\n",
    "        for i in range(0, 3):\n",
    "            idx_splits[i] = [num for sublist in idx_splits[i] for num in sublist]\n",
    "            idx_splits[i] = np.asarray(idx_splits[i])\n",
    "\n",
    "    return idx_splits"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ee4acb8-7806-4dc5-bc51-d8a087f9f858",
   "metadata": {},
   "source": [
    "pat_splits = [np.asarray([2, 4, 18, 17, 12, 10, 6, 0, 11, 16, 9, 14, 5, 19]), np.asarray([3, 13]), np.asarray([8, 7, 1, 15])]\n",
    "dataset_dir = \"/data/gpfs/projects/punim1836/Data/divided/17617648/\"\n",
    "rescaled_size = (176, 176, 48)\n",
    "data_splits = get_data_splits(pat_splits, split=True, aug_num=50)\n",
    "\n",
    "x_train, y_train, res_train, x_val, y_val, res_val, x_test, y_test, res_test = load_dataset_divide(dataset_dir, rescaled_size, data_splits)\n",
    "\n",
    "# move channel forward\n",
    "x_train = np.transpose(x_train, (0,4,1,2,3))\n",
    "x_val = np.transpose(x_val, (0,4,1,2,3))\n",
    "x_test = np.transpose(x_test, (0,4,1,2,3))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e1c5743-c626-4dee-ac2d-5510983534c7",
   "metadata": {},
   "source": [
    "column_size, row_size, slice_size = 88, 176, 48\n",
    "\n",
    "res_train = (res_train / [2/column_size, 2/row_size, 2/slice_size]).astype('float32')\n",
    "res_val = (res_val / [2/column_size, 2/row_size, 2/slice_size]).astype('float32')\n",
    "res_test = (res_test / [2/column_size, 2/row_size, 2/slice_size]).astype('float32')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2146cdb0-9fb5-45bd-a77f-29d61d9a2682",
   "metadata": {},
   "source": [
    "# transfer the Y\n",
    "image_size = [88, 176, 48]\n",
    "\n",
    "y_train_t = (y_train * 2 + 1) / np.asarray(image_size) - 1\n",
    "y_train_res = np.concatenate((y_train_t, res_train), axis=1)\n",
    "y_val_t = (y_val * 2 + 1) / np.asarray(image_size) - 1\n",
    "y_val_res = np.concatenate((y_val_t, res_val), axis=1)\n",
    "y_test_t = (y_test * 2 + 1) / np.asarray(image_size) - 1\n",
    "y_test_res = np.concatenate((y_test_t, res_test), axis=1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0004ce24-2d83-409f-9e84-b1a21bd2a567",
   "metadata": {},
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, X, Y, transform=None, target_transform=None):\n",
    "        self.img = X\n",
    "        self.img_labels = Y\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.img[idx]\n",
    "        label = self.img_labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29546ff7-49f3-4869-831a-1b18dae141ca",
   "metadata": {},
   "source": [
    "train_dataset = CustomImageDataset(x_train, y_train_res)\n",
    "val_dataset = CustomImageDataset(x_val, y_val_res)\n",
    "test_dataset = CustomImageDataset(x_test, y_test_res)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6500778-c3dc-43dd-93b8-822d859a4476",
   "metadata": {},
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=2, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=2, shuffle=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13600de5-9732-43ed-bbe0-3ea8d2e97fb9",
   "metadata": {},
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da2472d4-b736-41c6-86d9-386cc44213f7",
   "metadata": {},
   "source": [
    "## Prepare Model\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "727350f2-a217-429b-a05b-c961a13f48fd",
   "metadata": {},
   "source": [
    "class FCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv3d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm3d(16),\n",
    "            nn.Conv3d(16, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm3d(16),\n",
    "            nn.Conv3d(16, 16, kernel_size=3, padding=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf086d4e-f30d-428a-8444-2416e185f74b",
   "metadata": {},
   "source": [
    "kernel_size = 5\n",
    "\n",
    "class FCN1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv3d(1, 32, kernel_size=kernel_size, padding=\"same\"),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(32, 64, kernel_size=kernel_size, padding=\"same\"),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(64, 128, kernel_size=kernel_size, padding=\"same\"),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(128, 64, kernel_size=kernel_size, padding=\"same\"),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(64, 128, kernel_size=kernel_size, padding=\"same\"),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(128, 64, kernel_size=kernel_size, padding=\"same\"),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "418a8624-255d-4ca6-aee0-fa0d765405b1",
   "metadata": {},
   "source": [
    "import dsntnn\n",
    "\n",
    "class CoordRegressionNetwork(nn.Module):\n",
    "    def __init__(self, n_locations):\n",
    "        super().__init__()\n",
    "        self.fcn = FCN1()\n",
    "        self.hm_conv = nn.Conv3d(64, n_locations, kernel_size=1, bias=False)\n",
    "\n",
    "    def forward(self, images):\n",
    "        # 1. Run the images through our FCN\n",
    "        fcn_out = self.fcn(images)\n",
    "        # 2. Use a 1x1 conv to get one unnormalized heatmap per location\n",
    "        unnormalized_heatmaps = self.hm_conv(fcn_out)\n",
    "        # 3. Normalize the heatmaps\n",
    "        heatmaps = dsntnn.flat_softmax(unnormalized_heatmaps)\n",
    "        # 4. Calculate the coordinates\n",
    "        coords = dsntnn.dsnt(heatmaps)\n",
    "\n",
    "        return coords, heatmaps"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66cce3c0-df3f-4a8a-bbe4-53f57e059fea",
   "metadata": {},
   "source": [
    "## Loss Function\n",
    "def mse_with_res(y_true, y_pred, res):\n",
    "    \"\"\"\n",
    "    :param y_true: [batch_size, num_landmarks, dimension(column, row, slice)]\n",
    "    :param y_pred: [batch_size, num_landmarks, dimension(column, row, slice)]\n",
    "    :param res: Pixel distance in mm, [batch_size, 1, dimension(column, row, slice)]\n",
    "    :return: mean square error along batch_size (mm^2)\n",
    "    \"\"\"\n",
    "    err_diff = y_true - y_pred\n",
    "    # repeat res to make a convenient calculation follow\n",
    "    num_landmarks = err_diff.shape[1]\n",
    "    rep_res = torch.repeat_interleave(res, num_landmarks, axis=1)\n",
    "    # change pixel distance to mm (kind of normalization I think)\n",
    "    losses = err_diff\n",
    "    disses = err_diff * rep_res\n",
    "    square_losses = torch.pow(losses, 2)\n",
    "    square_disses = torch.pow(disses, 2 )\n",
    "    #loss = torch.mean(torch.sum(square_losses, (1, 2)))\n",
    "    loss = torch.sum(square_losses, (1, 2))\n",
    "    diss = torch.sum(square_disses, (1, 2))\n",
    "    return loss, diss"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e72c8fc-f682-416d-ba94-ee701e8ef093",
   "metadata": {},
   "source": [
    "model = CoordRegressionNetwork(n_locations=2).to(device)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c898a00b-ab95-4ca5-ae25-1bb80049e56f",
   "metadata": {},
   "source": [
    "train_features_var = train_features.cuda()\n",
    "coords, heatmaps = model(train_features_var)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9aac085-062c-4743-8eb2-9a56b49ae56a",
   "metadata": {},
   "source": [
    "y = train_labels[:, 0:2, :]\n",
    "res = train_labels[:, 2:3, :]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "196f39a6-5edd-490d-8be8-c8939a1cde21",
   "metadata": {},
   "source": [
    "y_var = y.cuda()\n",
    "res_var = res.cuda()\n",
    "mse_with_res(y_var, coords, res_var)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c9084b8a-a600-47c9-a417-74377f341c0e",
   "metadata": {},
   "source": [
    "def loss_fn(y_pred, heatmaps, y_true_res):\n",
    "    y_true = y_true_res[:, 0:2, :]\n",
    "    res = y_true_res[:, 2:3, :]\n",
    "    \n",
    "    # Per-location euclidean losses\n",
    "    # euc_losses = dsntnn.euclidean_losses(coords, pts_tensor_var)\n",
    "    euc_losses, dist = mse_with_res(y_true, y_pred, res)\n",
    "    # Per-location regularization losses\n",
    "    reg_losses = dsntnn.js_reg_losses(heatmaps, y_true, sigma_t=1.0)\n",
    "    # Combine losses into an overall loss\n",
    "    loss = dsntnn.average_loss(euc_losses)\n",
    "    euc_mean = dsntnn.average_loss(dist)\n",
    "    reg_mean = dsntnn.average_loss(reg_losses)\n",
    "    return loss, euc_mean, reg_mean"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd2a3379-c1bf-4f65-9d1f-04cb8d86bd30",
   "metadata": {},
   "source": [
    "## Training\n",
    "from torch import optim\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred, heat = model(X)\n",
    "        loss, dis, reg = loss_fn(pred, heat, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}] ({dis:>7f} / {reg:>5f})\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, dis_loss, reg_loss = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred, heat = model(X)\n",
    "            loss, dis, reg = loss_fn(pred, heat, y)\n",
    "            test_loss += loss.item()\n",
    "            dis_loss += dis.item()\n",
    "            reg_loss += reg.item()\n",
    "            #test_loss += loss_fn(pred, heat, y).item()\n",
    "    test_loss /= num_batches\n",
    "    dis_loss /= num_batches\n",
    "    reg_loss /= num_batches\n",
    "    print(f\"Test Error: \\nAvg loss: {test_loss:>8f}  Avg dis: {dis_loss:>8f}, Avg reg: {reg_loss:>8f}\\n\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8cea8bc9-9d8a-4fb7-aaa0-299343d7ce0d",
   "metadata": {},
   "source": [
    "model = CoordRegressionNetwork(n_locations=2).to(device)\n",
    "\n",
    "opt_rms = optim.RMSprop(model.parameters(), lr=0.0001)\n",
    "opt_ada = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, opt_ada)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd046ad-ba1a-4c27-9116-b3fd08c796bc",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
